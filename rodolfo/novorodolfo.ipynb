{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coisas para se fazer:\n",
    "1. Criar um teste para identificar a correlação entre as variáveis preditoras;\n",
    "2. Testar diferentes métodos de oversampling e undersampling\n",
    "3. Criar uma simulação que gera um classificador para cada train/test split e fornece uma decisão   baseado nessa de classificadores gerados\n",
    "4. Analisar os resultados de diferentes classificadores para indentificar as características de que \n",
    "exemplos os classificadores estão divergindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import seaborn as sns, pandas as pd, numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, PolynomialFeatures, PowerTransformer\n",
    "from sklearn.metrics import make_scorer,f1_score,accuracy_score,confusion_matrix,roc_auc_score,roc_curve, recall_score,precision_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import f_oneway, kruskal,chi2_contingency\n",
    "import scikit_posthocs as sp \n",
    "    \n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE, KMeansSMOTE \n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours, NeighbourhoodCleaningRule, OneSidedSelection\n",
    "\n",
    "import json\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def minha_metrica(y_true, y_pred):\n",
    "    threshold = 0.5  # Defina o threshold desejado\n",
    "    \n",
    "\n",
    "    # Calcule o true positive rate para o threshold dado\n",
    "    tp = np.sum((y_true == 1) & (y_pred >= threshold))\n",
    "    fn = np.sum((y_true == 1) & (y_pred < threshold))\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    # Calcule o true negative rate para o threshold dado\n",
    "    tn = np.sum((y_true == 0) & (y_pred < threshold))\n",
    "    fp = np.sum((y_true == 0) & (y_pred >= threshold))\n",
    "    tnr = tn / (tn + fp)\n",
    "\n",
    "    # Calcule o produto dos passos 1 e 2\n",
    "    product = tpr * tnr\n",
    "\n",
    "    # Retorne a raiz quadrada do passo 3\n",
    "    return np.sqrt(product)\n",
    "\n",
    "def geo_score(y_true, y_pred):\n",
    "    # Calcule o true positive rate para o threshold dado\n",
    "    tp = np.sum((y_true == 1) & (y_pred==1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred==0))\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    # Calcule o true negative rate para o threshold dado\n",
    "    tn = np.sum((y_true == 0) & (y_pred==0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred==1))\n",
    "    tnr = tn / (tn + fp)\n",
    "\n",
    "    # Calcule o produto dos passos 1 e 2\n",
    "    product = tpr * tnr\n",
    "\n",
    "    # Retorne a raiz quadrada do passo 3\n",
    "    return np.sqrt(product)\n",
    "\n",
    "def minha_metrica_c(y_true, y_pred,threshold = 0.5):\n",
    "    \n",
    "\n",
    "    # Calcule o true positive rate para o threshold dado\n",
    "    tp = np.sum((y_true == 1) & (y_pred >= threshold))\n",
    "    fn = np.sum((y_true == 1) & (y_pred < threshold))\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    # Calcule o true negative rate para o threshold dado\n",
    "    tn = np.sum((y_true == 0) & (y_pred < threshold))\n",
    "    fp = np.sum((y_true == 0) & (y_pred >= threshold))\n",
    "    tnr = tn / (tn + fp)\n",
    "\n",
    "    # Calcule o produto dos passos 1 e 2\n",
    "    product = tpr * tnr\n",
    "\n",
    "    # Retorne a raiz quadrada do passo 3\n",
    "    return np.sqrt(product)\n",
    "\n",
    "def get_scores(y_true_tr,y_pred_tr,y_true_ts,y_pred_ts,scorers=[\"roc_auc_score\",\"accuracy_score\",\"precision_score\",\"recall_score\",\"f1_score\"]):\n",
    "    nomes, vtest,vtrain = [],[],[]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true_tr, y_pred_tr)\n",
    "    distances = (fpr - 0)**2 + (tpr - 1)**2\n",
    "    index = distances.argmin()\n",
    "    corte = thresholds[index]\n",
    "    fprts, tprts, thresholdsts = roc_curve(y_true_ts, y_pred_ts)\n",
    "\n",
    "    for sc in scorers:\n",
    "        if sc.__name__ in [\"roc_auc_curve\"]:\n",
    "            vtest.append(sc(y_true_ts,y_pred_ts))\n",
    "            vtrain.append(sc(y_true_tr,y_pred_tr))\n",
    "            nomes.append(sc.__name__)\n",
    "        elif sc.__name__ in [\"minha_metrica_c\"]:\n",
    "            vtest.append(sc(y_true_ts, y_pred_ts,threshold = corte))\n",
    "            vtrain.append(sc(y_true_tr, y_pred_tr,threshold = corte))\n",
    "            nomes.append(sc.__name__)\n",
    "        else:\n",
    "            vtest.append(sc(y_true_ts,y_pred_ts>=corte))\n",
    "            vtrain.append(sc(y_true_tr,y_pred_tr>=corte))\n",
    "            nomes.append(sc.__name__)    \n",
    "    \n",
    "    metricas = pd.DataFrame({\"metrica\":nomes,\"valor no treino\":vtrain,\"valor no teste\":vtest})\n",
    "    roc_curve_train = {\"fpr\":fpr,\"tpr\":tpr,\"thresholds\":thresholds,\"corte\":corte} \n",
    "    roc_curve_test = {\"fpr\":fprts,\"tpr\":tprts,\"thresholds\":thresholdsts}\n",
    "    cm1 = confusion_matrix(y_pred=y_pred_ts>=corte,y_true=y_true_ts)\n",
    "    cm2 = confusion_matrix(y_pred=y_pred_ts>=corte,y_true=y_true_ts,normalize='true')\n",
    "    cm = pd.DataFrame({\"pred_0\":[cm1[0][0],cm1[1][0]],\"pred_1\":[cm1[0][1],cm1[1][1]],\"predn_0\":[cm2[0][0],cm2[1][0]],\"predn_1\":[cm2[0][1],cm2[1][1]]},index=[\"true 0\",\"true_1\"])\n",
    "    res = {\"metricas\":metricas,\"roc_curve_train\":roc_curve_train,\"roc_curve_test\":roc_curve_test,\"melhor\":[fpr[index],tpr[index],corte],\"confusion_matrix\":cm}\n",
    "    return res\n",
    "\n",
    "def meu_enconder(data,columns,target,split = False,rnd_state=None):\n",
    "    mapa = {}\n",
    "    if split:\n",
    "        data_train,data_test = train_test_split(data,test_size=0.2,stratify=data[target],random_state=rnd_state)\n",
    "        for cl in columns:\n",
    "            # contagemp = data_train.groupby(cl)[target].value_counts(normalize=True).unstack().fillna(0)\n",
    "            contagemp = data_train.groupby(cl)[target].value_counts(normalize=True).unstack().fillna(0)\n",
    "            # contagemp[\"log\"] = np.log(contagemp[1]/contagemp[0])\n",
    "            idx = contagemp.sort_values(by=1,ascending=False).index\n",
    "            mapeamento = {v:i for i,v in enumerate(idx)}\n",
    "            mapeamento_inverso = {i:v for i,v in enumerate(idx)} \n",
    "            data_train[cl] = data_train[cl].map(mapeamento)\n",
    "            data_test[cl] = data_test[cl].map(mapeamento)\n",
    "            mapa[cl]= {\"mapa\":mapeamento,\"mapa_inverso\":mapeamento_inverso}\n",
    "            data_test = data_test.dropna()\n",
    "        return {\"train\":data_train,\"test\":data_test,\"mapas\":mapa}\n",
    "    else:\n",
    "        ndata = data.copy()\n",
    "        for cl in columns:\n",
    "            contagemp = data.groupby(cl)[target].value_counts(normalize=True).unstack().fillna(0)\n",
    "            # contagemp[\"log\"] = np.log(contagemp[1]/contagemp[0])\n",
    "            idx = contagemp.sort_values(by=1,ascending=False).index\n",
    "            mapeamento = {v:i for i,v in enumerate(idx)} \n",
    "            mapeamento_inverso = {i:v for i,v in enumerate(idx)} \n",
    "            ndata[cl] = data[cl].map(mapeamento).astype(int)\n",
    "            mapa[cl]= {\"mapa\":mapeamento,\"mapa_inverso\":mapeamento_inverso}\n",
    "        return {\"data\":ndata,\"mapas\":mapa}\n",
    "\n",
    "def categorizar(data,columns):\n",
    "    ndata = data.copy()\n",
    "    intervalos = {}\n",
    "    for cl in columns:\n",
    "        if data[cl].dtypes in [np.int64,np.int32,np.float64]:\n",
    "            categories = pd.qcut(data[cl],10,duplicates='drop')\n",
    "            labels, unicos = pd.factorize(categories, sort=True)\n",
    "            mapa = {f'{i}': [un.left, un.right] for i, un in enumerate(unicos)}\n",
    "            intervalos[cl] = mapa\n",
    "            ndata[f\"{cl}_cat\"] = labels\n",
    "    return {\"data\":ndata,\"intervalos\":intervalos}\n",
    "\n",
    "def significancia(data,predictors,target,alpha=0.1):\n",
    "    pval,tval,sigval = [],[],[]\n",
    "    myvars = list(predictors.keys())\n",
    "    for cl in myvars:\n",
    "        if predictors[cl]:\n",
    "            contingency_table = pd.crosstab(data[cl], data[target])\n",
    "            chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "            pval.append(p)\n",
    "            tval.append(chi2)\n",
    "            sigval.append(p<alpha)\n",
    "        else:\n",
    "            groups = []\n",
    "            gpstat = data.groupby(target)\n",
    "            for key in gpstat.groups.keys():\n",
    "                groups.append(gpstat.get_group(key)[cl])\n",
    "            f_statistic, p = kruskal(*groups)\n",
    "            pval.append(p)\n",
    "            tval.append(f_statistic)\n",
    "            sigval.append(p<alpha)\n",
    "    significantvar = list([myvars[i] for i,v in enumerate(sigval) if v])\n",
    "    stats = pd.DataFrame({\"variable\":myvars,\"test-value\":tval,\"p-value\":pval,\"significance\":sigval})\n",
    "    return {\"stats\":stats,\"significantes\":significantvar}\n",
    "\n",
    "def simulador(estimator,data,predictors,target,nsim,metricas=[geo_score,f1_score,accuracy_score,roc_auc_score]):\n",
    "    metricasval = np.zeros((nsim,len(metricas)))\n",
    "    truepos,trueneg = [],[]\n",
    "    res = {}\n",
    "    for i in range(nsim):\n",
    "        data_train,data_test = train_test_split(data,test_size=0.2, stratify=data[target])\n",
    "        X_train,y_train = data_train[predictors],data_train[target]\n",
    "        X_test,y_test = data_test[predictors],data_test[target]\n",
    "\n",
    "        bests = estimator.fit(X_train,y_train)\n",
    "        try:\n",
    "            y_pred_ts = bests.predict_proba(X_test)[:,1]\n",
    "            y_pred_tr = bests.predict_proba(X_train)[:,1]\n",
    "        except:\n",
    "            y_pred_ts = bests.decision_function(X_test)\n",
    "            y_pred_tr = bests.decision_function(X_train)\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_train, y_pred_tr)\n",
    "        distances = (fpr - 0)**2 + (tpr - 1)**2\n",
    "        index = distances.argmin()\n",
    "        corte = thresholds[index]\n",
    "        cm = confusion_matrix(y_pred=y_pred_ts>=corte,y_true=y_test,normalize='true')\n",
    "        truepos.append(cm[1][1])\n",
    "        trueneg.append(cm[0][0])\n",
    "        for j,mtr in enumerate(metricas):\n",
    "            if mtr.__name__ in [\"roc_auc_curve\"]:\n",
    "                metricasval[i,j] = mtr(y_test,y_pred_ts)\n",
    "            else:\n",
    "                metricasval[i,j] = mtr(y_test,y_pred_ts>=corte)\n",
    "    \n",
    "    res[\"tpr\"] = truepos\n",
    "    res[\"tnr\"] = trueneg\n",
    "    for j,mtr in enumerate(metricas):\n",
    "        res[mtr.__name__] = metricasval[:,j]\n",
    "    return res\n",
    "\n",
    "def minha_anova(tabela,alpha = 0.05):\n",
    "    h_statistic, p_value = kruskal(*tabela)\n",
    "    if p_value>alpha:\n",
    "        return  {\"stats\":h_statistic,\"p_value\":p_value}\n",
    "    \n",
    "    else:\n",
    "        pvals = sp.posthoc_conover(tabela,p_adjust='holm').to_numpy()\n",
    "        ddif = {}\n",
    "        for i in range(pvals.shape[0]):\n",
    "            dff,deq = [],[]\n",
    "            for j in range(pvals.shape[1]):\n",
    "                if pvals[i,j]<alpha:\n",
    "                    dff.append(j)\n",
    "                else:\n",
    "                    deq.append(j)\n",
    "            ddif[i]={\"igual_idx\":deq,\"diferente_idx\":dff}\n",
    "        \n",
    "        return {\"stats\":ddif,\"p_value\":pvals}\n",
    "    \n",
    "def simulador_2(estimator,data,predictors,target,categoricalvar,nsim,metricas=[geo_score,f1_score,accuracy_score,roc_auc_score]):\n",
    "    metricasval = np.zeros((nsim,len(metricas)))\n",
    "    truepos,trueneg = [],[]\n",
    "    res = {}\n",
    "    for i in range(nsim):\n",
    "        # data_train,data_test = train_test_split(data,test_size=0.2, stratify=data[target])\n",
    "        encodar = [cl for cl in predictors if categoricalvar[cl]]\n",
    "        encodado = meu_enconder(data=data,columns=encodar,target=target,split=True)\n",
    "        data_train,data_test = encodado[\"train\"],encodado[\"test\"]\n",
    "\n",
    "\n",
    "        X_train,y_train = data_train[predictors],data_train[target]\n",
    "        X_test,y_test = data_test[predictors],data_test[target]\n",
    "        # print(X_test.isna().any())\n",
    "\n",
    "        search = cross_validate(estimator, X_train, y_train, scoring=roc_auc_score, cv = StratifiedKFold(5), return_estimator=True)\n",
    "        bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "        try:\n",
    "            y_pred_ts = bests.predict_proba(X_test)[:,1]\n",
    "            y_pred_tr = bests.predict_proba(X_train)[:,1]\n",
    "        except:\n",
    "            y_pred_ts = bests.decision_function(X_test)\n",
    "            y_pred_tr = bests.decision_function(X_train)\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_train, y_pred_tr)\n",
    "        distances = (fpr - 0)**2 + (tpr - 1)**2\n",
    "        index = distances.argmin()\n",
    "        corte = thresholds[index]\n",
    "        cm = confusion_matrix(y_pred=y_pred_ts>=corte,y_true=y_test,normalize='true')\n",
    "        truepos.append(cm[1][1])\n",
    "        trueneg.append(cm[0][0])\n",
    "        for j,mtr in enumerate(metricas):\n",
    "            if mtr.__name__ in [\"roc_auc_curve\"]:\n",
    "                metricasval[i,j] = mtr(y_test,y_pred_ts)\n",
    "            else:\n",
    "                metricasval[i,j] = mtr(y_test,y_pred_ts>=corte)\n",
    "    \n",
    "    res[\"tpr\"] = truepos\n",
    "    res[\"tnr\"] = trueneg\n",
    "    for j,mtr in enumerate(metricas):\n",
    "        res[mtr.__name__] = metricasval[:,j]\n",
    "    return res\n",
    "\n",
    "def agrupa_predicoes(estimator,data_train,data_test,predictors,target,categoricalvar,corte,alpha=0.05):\n",
    "    X_train,y_train = data_train[predictors],data_train[target]\n",
    "    # X_test,y_test = data_test[predictors],data_test[target]\n",
    "\n",
    "    # y_pred_test = estimator.predict_proba(X_test)[:,1]\n",
    "    # y_pred_train = estimator.predict_proba(X_train)[:,1]\n",
    "\n",
    "    y_pred_train = predicao(estimator,X_train)\n",
    "\n",
    "\n",
    "    data_train[\"compara\"]=((y_pred_train>=corte)==y_train).astype(int)\n",
    "    res_stat={}\n",
    "    pred_sep = []\n",
    "    for cl in predictors:\n",
    "        if categoricalvar[cl]:\n",
    "            contingency_table = pd.crosstab(data_train[cl], data_train[\"compara\"])\n",
    "            chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "            res_stat[cl]=[p, p<alpha]\n",
    "            if p<alpha:\n",
    "                pred_sep.append(cl)\n",
    "        else:\n",
    "            groups = []\n",
    "            gpstat = data_train.groupby(\"compara\")\n",
    "            for k in gpstat.groups.keys():\n",
    "                groups.append(gpstat.get_group(k)[cl])\n",
    "            f_statistic, p = kruskal(*groups)\n",
    "            res_stat[cl]=[p, p<alpha]\n",
    "            if p<alpha:\n",
    "                pred_sep.append(cl)\n",
    "    \n",
    "    pred_sep.append(\"compara\")\n",
    "\n",
    "    # pred_sep = [\"month\",\"no_exa_scheduled_previous_year\",\"compara\"]\n",
    "    normalizador = data_train[pred_sep[:-1]].max().to_numpy() \n",
    "    normalizador = np.ones(shape=(len(pred_sep[:-1]),))\n",
    "    g_tr_comp = data_train[pred_sep].groupby(\"compara\")\n",
    "    train_0_m = g_tr_comp.get_group(0).mean().to_numpy()[:-1]/normalizador\n",
    "    train_1_m = g_tr_comp.get_group(1).mean().to_numpy()[:-1]/normalizador\n",
    "    \n",
    "    separa = []\n",
    "    for y in data_test.index:\n",
    "        x = data_test[pred_sep[:-1]].loc[y,:].to_numpy()/normalizador\n",
    "        n0 = np.linalg.norm(x-train_0_m,1)\n",
    "        n1 = np.linalg.norm(x-train_1_m,1)\n",
    "        separa.append(0*(n1>=n0)+1*(n1<n0))\n",
    "\n",
    "    data_test[\"separa\"] = separa\n",
    "\n",
    "    X_train_0 = data_train.groupby(\"compara\").get_group(0)[predictors]\n",
    "    X_train_1 = data_train.groupby(\"compara\").get_group(1)[predictors]\n",
    "    \n",
    "    y_train_0 = data_train.groupby(\"compara\").get_group(0)[target]\n",
    "    y_train_1 = data_train.groupby(\"compara\").get_group(1)[target]\n",
    "    \n",
    "    X_test_0 = data_test.groupby(\"separa\").get_group(0)[predictors]\n",
    "    X_test_1 = data_test.groupby(\"separa\").get_group(1)[predictors]\n",
    "    \n",
    "    y_test_0 = data_test.groupby(\"separa\").get_group(0)[target]\n",
    "    y_test_1 = data_test.groupby(\"separa\").get_group(1)[target]\n",
    "\n",
    "    y_pred_train_0 = predicao(estimator,X_train_0)\n",
    "    y_pred_train_1 = predicao(estimator,X_train_1)\n",
    "    \n",
    "    y_pred_test_0 = predicao(estimator,X_test_0)\n",
    "    y_pred_test_1 = predicao(estimator,X_test_1)\n",
    "    \n",
    "    roc_esc_ts_1 = roc_auc_score(y_test_1,y_pred_test_1)\n",
    "    roc_esc_ts_0 = roc_auc_score(y_test_0,y_pred_test_0)\n",
    "    \n",
    "    roc_esc_tr_1 = roc_auc_score(y_train_1,y_pred_train_1)\n",
    "    roc_esc_tr_0 = roc_auc_score(y_train_0,y_pred_train_0)\n",
    "    \n",
    "    fpr_tr0,tpr_tr0,_ = roc_curve(y_train_0,y_pred_train_0)\n",
    "    fpr_tr1,tpr_tr1,_ = roc_curve(y_train_1,y_pred_train_1)\n",
    "    \n",
    "    fpr_ts1,tpr_ts1,_ = roc_curve(y_test_1,y_pred_test_1)\n",
    "    fpr_ts0,tpr_ts0,_ = roc_curve(y_test_0,y_pred_test_0)\n",
    "\n",
    "    curvas_roc = {\"train_0\":[fpr_tr0,tpr_tr0],\"train_1\":[fpr_tr1,tpr_tr1],\"test_0\":[fpr_ts0,tpr_ts0],\"test_1\":[fpr_ts1,tpr_ts1]}\n",
    "    metrs = {\"train_0\":roc_esc_tr_0,\"train_1\":roc_esc_tr_1,\"test_0\":roc_esc_ts_0,\"test_1\":roc_esc_ts_1}\n",
    "    return {\"data\":{\"train\":data_train,\"test\":data_test},\"curva_roc\":curvas_roc,\"metricas\":metrs,\"separador\":pred_sep}\n",
    "\n",
    "def salvarpipes(nome,mypipe,filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            existing_data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        existing_data = {}\n",
    "        # bests.named_steps[\"modelo\"].__str__().split(\"(\")[0]\n",
    "        # bests.named_steps[\"modelo\"].get_params()\n",
    "\n",
    "    \n",
    "    dicio = {}\n",
    "    for name, step in mypipe.named_steps.items():\n",
    "        # dicio[name] =  step.__str__().replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "        dicio[name] =  {\"estimator\":json.dumps(step.__str__().split(\"(\")[0]),\"params\":json.dumps(step.get_params())}\n",
    "\n",
    "\n",
    "    existing_data[nome] = dicio\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(existing_data, file)\n",
    "\n",
    "\n",
    "def predicao(estimator, X):\n",
    "    if hasattr(estimator, 'predict_proba'):\n",
    "        return estimator.predict_proba(X)[:,1]\n",
    "    elif hasattr(estimator, 'decision_function'):\n",
    "        return estimator.decision_function(X)\n",
    "    else:\n",
    "        raise AttributeError(\"Estimator does not have predict_proba or decision_function method.\")\n",
    "\n",
    "def feat_transform(dados,columns,target,categoricalvar):\n",
    "    for cl in columns:\n",
    "        if categoricalvar[cl]:\n",
    "            contagemp = dados.groupby(cl)[target].value_counts(normalize=True).unstack().fillna(0)\n",
    "            idx = contagemp.sort_values(by=1,ascending=False).index\n",
    "            lcnty,yb = list(contagemp[1]),list(dados[cl])\n",
    "            y0,y1 = lcnty[0],lcnty[-1]\n",
    "            m = y1-y0            \n",
    "            xb =[np.abs((lcnty[id]-y0)/m) for id in yb]\n",
    "            dados[f\"{cl}_t\"] = xb\n",
    "    return dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dados_hospital.csv\", sep=',')\n",
    "data.dropna(inplace=True)\n",
    "target = 'no_show'\n",
    "mapeamento = {'SIM': 0, 'NÃO': 1}\n",
    "data[target] = data[target].map(mapeamento).astype(int)\n",
    "data = data[data[\"distance\"]<1000]\n",
    "original_columns = list(data.columns[:-1])\n",
    "\n",
    "categoricalvar = {cl:data[cl].dtypes == np.object0 for cl in original_columns} \n",
    "\n",
    "categs = categorizar(data=data,columns=[cl for cl in original_columns if not categoricalvar[cl]])\n",
    "data = categs[\"data\"]\n",
    "\n",
    "encodar = [cl for cl in original_columns if categoricalvar[cl]]\n",
    "for cl in encodar:\n",
    "    data[cl] = LabelEncoder().fit_transform(data[cl])\n",
    "\n",
    "res = significancia(data,categoricalvar,target)\n",
    "predictors = res[\"significantes\"]\n",
    "\n",
    "data_train,data_test = train_test_split(data,test_size=0.2,stratify=data[target],random_state=None)\n",
    "data_train = feat_transform(data_train,encodar,target,categoricalvar)\n",
    "X_train,y_train = data_train[predictors],data_train[target]\n",
    "X_test,y_test = data_test[predictors],data_test[target]\n",
    "\n",
    "my_scorer,my_scorer_m = make_scorer(roc_auc_score,greater_is_better=True), make_scorer(minha_metrica,greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670     1.000000\n",
       "1214    0.602598\n",
       "7624    1.374605\n",
       "7699    0.000000\n",
       "3647    0.000000\n",
       "          ...   \n",
       "510     0.000000\n",
       "5712    0.000000\n",
       "4009    1.374605\n",
       "7552    1.374605\n",
       "4202    0.334525\n",
       "Name: marital_status_t, Length: 6704, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"marital_status_t\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dados_hospital.csv\", sep=',')\n",
    "data.dropna(inplace=True)\n",
    "target = 'no_show'\n",
    "mapeamento = {'SIM': 0, 'NÃO': 1}\n",
    "data[target] = data[target].map(mapeamento).astype(int)\n",
    "data = data[data[\"distance\"]<1000]\n",
    "original_columns = list(data.columns[:-1])\n",
    "\n",
    "categoricalvar = {cl:data[cl].dtypes == np.object0 for cl in original_columns} \n",
    "\n",
    "categs = categorizar(data=data,columns=[cl for cl in original_columns if not categoricalvar[cl]])\n",
    "data = categs[\"data\"]\n",
    "\n",
    "encodar = [cl for cl in original_columns if categoricalvar[cl]]+[f\"{cl}_cat\" for cl in original_columns if not categoricalvar[cl]]\n",
    "encodado = meu_enconder(data=data,columns=encodar,target=target,split=True)\n",
    "data_train,data_test = encodado[\"train\"],encodado[\"test\"]\n",
    "\n",
    "res = significancia(data,categoricalvar,target)\n",
    "predictors = res[\"significantes\"]\n",
    "\n",
    "X_train,y_train = data_train[predictors],data_train[target]\n",
    "X_test,y_test = data_test[predictors],data_test[target]\n",
    "\n",
    "my_scorer,my_scorer_m = make_scorer(roc_auc_score,greater_is_better=True), make_scorer(minha_metrica,greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(data_train['no_exa_scheduled_previous_year'],data_train['no_ns_cons_previous_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cat = ['age_cat', 'distance_cat', 'lead_time_cat',\n",
    "       'no_cons_scheduled_previous_year_cat', 'no_ns_cons_previous_year_cat',\n",
    "       'no_exa_scheduled_previous_year_cat', 'no_ns_exa_previous_year_cat']\n",
    "for cl in var_cat:\n",
    "    contagemp = data_train.groupby(cl)[target].value_counts(normalize=True).unstack().fillna(0)\n",
    "    idx = contagemp.sort_values(by=1,ascending=False).index\n",
    "    mapeamento = {v:i for i,v in enumerate(idx)} \n",
    "    data_train[f\"{cl}_cat2\"] = data_train[cl].map(mapeamento).astype(int)\n",
    "    data_test[f\"{cl}_cat2\"] = data_test[cl].map(mapeamento).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,3)\n",
    "ax = ax.flatten()\n",
    "i = 0\n",
    "for cl in predictors:\n",
    "    sns.histplot(x=cl,data=data_train,ax=ax[i])\n",
    "    i = i+1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,2)\n",
    "ax = ax.flatten()\n",
    "i = 0\n",
    "for cl in predictors:\n",
    "    if categoricalvar[cl]:\n",
    "        contagemp = data_train.groupby(cl)[target].value_counts(normalize=True).unstack().fillna(0)\n",
    "        sns.scatterplot(x=cl,y=1,data=contagemp,ax=ax[i])\n",
    "        i = i+1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,2)\n",
    "ax = ax.flatten()\n",
    "i = 0\n",
    "for cl in predictors:\n",
    "    if not categoricalvar[cl]:\n",
    "        contagemp = data_train.groupby(f\"{cl}_cat\")[target].value_counts(normalize=True).unstack().fillna(0)\n",
    "        sns.scatterplot(x=f\"{cl}_cat\",y=1,data=contagemp,ax=ax[i],color=\"red\")\n",
    "        sns.lineplot(x=f\"{cl}_cat\",y=1,data=contagemp,ax=ax[i],linestyle='dashed')\n",
    "        i = i+1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = \"age_cat\"\n",
    "grau = 2\n",
    "contagemp = data_train.groupby(cls)[target].value_counts(normalize=True).unstack().fillna(0)\n",
    "aa = np.polyfit(np.array(contagemp.index),np.array(contagemp[1]),grau)\n",
    "xxp = np.array(contagemp.index)\n",
    "yyp  = np.sum([par*xxp**(grau-i) for i,par in enumerate(aa)],axis=0)\n",
    "sns.scatterplot(x=cls,y=1,data=contagemp,color=\"red\")\n",
    "sns.lineplot(x=cls,y=1,data=contagemp,linestyle='dashed')\n",
    "sns.lineplot(x=xxp,y=yyp)\n",
    "\n",
    "data_train[\"age_2\"] = np.sum([par*data_train[\"age\"]**(grau-i) for i,par in enumerate(aa)],axis=0)\n",
    "data_test[\"age_2\"] = np.sum([par*data_test[\"age\"]**(grau-i) for i,par in enumerate(aa)],axis=0)\n",
    "\n",
    "cls = \"distance_cat\"\n",
    "grau = 2\n",
    "contagemp = data_train.groupby(cls)[target].value_counts(normalize=True).unstack().fillna(0)\n",
    "aa = np.polyfit(np.array(contagemp.index),np.array(contagemp[1]),grau)\n",
    "xxp = np.array(contagemp.index)\n",
    "yyp  = np.sum([par*xxp**(grau-i) for i,par in enumerate(aa)],axis=0)\n",
    "sns.scatterplot(x=cls,y=1,data=contagemp,color=\"red\")\n",
    "sns.lineplot(x=cls,y=1,data=contagemp,linestyle='dashed')\n",
    "sns.lineplot(x=xxp,y=yyp)\n",
    "\n",
    "data_train[\"distance_2\"] = np.sum([par*data_train[\"distance\"]**(grau-i) for i,par in enumerate(aa)],axis=0)\n",
    "data_test[\"distance_2\"] = np.sum([par*data_test[\"distance\"]**(grau-i) for i,par in enumerate(aa)],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contagemp = data_train.groupby(\"marital_status\")[target].value_counts(normalize=True).unstack().fillna(0)\n",
    "            # contagemp[\"log\"] = np.log(contagemp[1]/contagemp[0])\n",
    "idx = contagemp.sort_values(by=1,ascending=False).index\n",
    "list(contagemp[1])[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classifier \n",
    "vizinhos = 35\n",
    "pipe = Pipeline([('escala',StandardScaler()),('modelo', KNeighborsClassifier(n_neighbors=vizinhos))])\n",
    "\n",
    "search = cross_validate(pipe, X_train, y_train, scoring=my_scorer, cv=3, return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "# bests = pipe.fit(X_train, y_train)\n",
    "\n",
    "# coeficientes = pd.DataFrame({\"variável\":pipe.named_steps[\"poly\"].get_feature_names_out().ravel,\"coeficientes\":bests.named_steps[\"modelo\"].coef_.ravel()})\n",
    "# print(f\"{coeficientes}\\n\")\n",
    "\n",
    "y_pred_test = bests.predict_proba(X_test)[:,1]\n",
    "y_pred_train = bests.predict_proba(X_train)[:,1]\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "pipe = Pipeline([('poly',PolynomialFeatures(5)),('escala',MinMaxScaler()),('modelo', LogisticRegression(penalty='l2',class_weight='balanced',C = 1.0e-5,max_iter=1000000))])\n",
    "\n",
    "# pipe = Pipeline([('escala',MinMaxScaler()),('modelo', LogisticRegression(penalty='l2',class_weight='balanced',C = 1.0e-15,max_iter=1000000))])\n",
    "\n",
    "search = cross_validate(pipe, X_train, y_train, scoring=my_scorer, cv=3, return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "# bests = pipe.fit(X_train, y_train)\n",
    "\n",
    "# coeficientes = pd.DataFrame({\"variável\":pipe.named_steps[\"poly\"].get_feature_names_out().ravel,\"coeficientes\":bests.named_steps[\"modelo\"].coef_.ravel()})\n",
    "# print(f\"{coeficientes}\\n\")\n",
    "\n",
    "y_pred_test = bests.decision_function(X_test)\n",
    "y_pred_train = bests.decision_function(X_train)\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Classifier\n",
    "# pipe = Pipeline([('poly',PolynomialFeatures(2)),('escala',MinMaxScaler()),('modelo', LogisticRegression(penalty='l2',class_weight='balanced',C = 1.0e-2,max_iter=1000000))])\n",
    "\n",
    "alpha = 1e-0\n",
    "max_iter = 5000\n",
    "loss = \"squared_hinge\"\n",
    "penalty = \"l2\"\n",
    "pipe = Pipeline([('escala',StandardScaler()),('modelo', SGDClassifier(loss=loss,penalty=penalty,class_weight='balanced',alpha = alpha,max_iter=max_iter))])\n",
    "\n",
    "search = cross_validate(pipe, X_train, y_train, scoring=my_scorer, cv=3, return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "# bests = pipe.fit(X_train, y_train)\n",
    "\n",
    "# coeficientes = pd.DataFrame({\"variável\":pipe.named_steps[\"poly\"].get_feature_names_out().ravel,\"coeficientes\":bests.named_steps[\"modelo\"].coef_.ravel()})\n",
    "# print(f\"{coeficientes}\\n\")\n",
    "\n",
    "y_pred_test = bests.decision_function(X_test)\n",
    "y_pred_train = bests.decision_function(X_train)\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression GridSearch\n",
    "param_grid = {\n",
    "    \"modelo__C\" :np.geomspace(1e-8,1e+2,50),\n",
    "    \"poly__degree\" :[1,2,4]\n",
    "}\n",
    "pipe = Pipeline([('poly',PolynomialFeatures()),('escala',MinMaxScaler()),('modelo', LogisticRegression(penalty='l2',class_weight='balanced',max_iter=1000000))])\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid,scoring = my_scorer, cv = 3, n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "bests = search.best_estimator_\n",
    "\n",
    "print(\"--melhor escore no cv--\")\n",
    "print(search.best_score_)\n",
    "\n",
    "print(\"\\n--parâmetros de melhor escore no cv--\") \n",
    "print(search.best_params_)\n",
    "\n",
    "# coeficientes = pd.DataFrame({\"variável\":predictors,\"coeficientes\":bests.named_steps[\"modelo\"].coef_})\n",
    "# print(f\"\\n{coeficientes}\")\n",
    "\n",
    "y_pred_test = bests.decision_function(X_test)\n",
    "y_pred_train = bests.decision_function(X_train)\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"\\n{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC Classifier\n",
    "\n",
    "ga = 'auto'\n",
    "dg = 1\n",
    "\n",
    "# pipe = Pipeline([('escala',MinMaxScaler()),('modelo', SVC(kernel='poly',class_weight='balanced',degree=dg,gamma=ga))])\n",
    "pipe = Pipeline([('escala',MinMaxScaler()),('modelo', SVC(kernel='rbf',class_weight='balanced',degree=dg,gamma=ga))])\n",
    "\n",
    "\n",
    "search = cross_validate(pipe, X_train, y_train, scoring=my_scorer, cv=7, return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "y_pred_test = bests.decision_function(X_test)\n",
    "y_pred_train = bests.decision_function(X_train)\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch SVC Classifier\n",
    "param_grid = {\n",
    "    \"modelo__gamma\" : list(np.geomspace(1e-5,1e+0,5))+['auto','scale'],\n",
    "    \"modelo__degree\":[1,2],\n",
    "    \"modelo__kernel\": [\"poly\",'rbf']\n",
    "}\n",
    "\n",
    "# pipe = Pipeline([('escala',MinMaxScaler()),('modelo', SVC(kernel='poly',class_weight='balanced'))])\n",
    "\n",
    "pipe = Pipeline([('escala',MinMaxScaler()),('modelo', SVC(class_weight='balanced'))])\n",
    "\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, scoring = my_scorer, cv = 5, n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "bests = search.best_estimator_\n",
    "\n",
    "y_pred_test = bests.decision_function(X_test)\n",
    "y_pred_train = bests.decision_function(X_train)\n",
    "\n",
    "print(f\"melhor score cv:\\n{search.best_score_}\\n\")\n",
    "print(f\"parâmetros melhor score cv:\\n{search.best_params_}\\n\")\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"melhor score cv:\\n{search.best_score_}\\n\")\n",
    "print(f\"parâmetros melhor score cv:\\n{search.best_params_}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "n_estimators = 5\n",
    "max_features = \"log2\"\n",
    "max_depth = 2\n",
    "\n",
    "pipe = Pipeline([('modelo', RandomForestClassifier(n_estimators=n_estimators,max_features=max_features,class_weight='balanced',max_depth=max_depth))])\n",
    "\n",
    "search = cross_validate(pipe, X_train, y_train, scoring=my_scorer, cv=7, return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "y_pred_test = bests.predict_proba(X_test)[:,1]\n",
    "y_pred_train = bests.predict_proba(X_train)[:,1]\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch Random Forest\n",
    "param_grid = {\n",
    "    'modelo__n_estimators': [2*n+1 for n in range(2,10)],\n",
    "    'modelo__max_features':[\"sqrt\", \"log2\"],\n",
    "    'modelo__max_depth': [2,3,4,5,7]\n",
    "    }\n",
    "\n",
    "pipe = Pipeline([('modelo', RandomForestClassifier(class_weight='balanced'))])\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, scoring = my_scorer, cv = 5, n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "bests = search.best_estimator_\n",
    "\n",
    "print(f\"melhor score cv:\\n{search.best_score_}\\n\")\n",
    "print(f\"parâmetros melhor score cv:\\n{search.best_params_}\\n\")\n",
    "\n",
    "y_pred_test = bests.predict_proba(X_test)[:,1]\n",
    "y_pred_train = bests.predict_proba(X_train)[:,1]\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch Random Forest com SAMPLING\n",
    "param_grid = {\n",
    "    'modelo__n_estimators': [2*n+1 for n in range(2,50)],\n",
    "    'modelo__max_features':[\"sqrt\", \"log2\"],\n",
    "    'modelo__max_depth': [2,3,4]\n",
    "    }\n",
    "\n",
    "pipe = Pipeline([('modelo', RandomForestClassifier(class_weight='balanced'))])\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, scoring = my_scorer, cv = 5, n_jobs=-1)\n",
    "\n",
    "sampler = RandomOverSampler()\n",
    "X_trans,y_trans = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "search.fit(X_trans, y_trans)\n",
    "bests = search.best_estimator_\n",
    "\n",
    "print(f\"melhor score cv:\\n{search.best_score_}\\n\")\n",
    "print(f\"parâmetros melhor score cv:\\n{search.best_params_}\\n\")\n",
    "\n",
    "y_pred_test = bests.predict_proba(X_test)[:,1]\n",
    "y_pred_train = bests.predict_proba(X_train)[:,1]\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validade Random Forest com SAMPLING \n",
    "n_estimators = 55\n",
    "max_features = \"log2\"\n",
    "max_depth = 3\n",
    "criterion = 'log_loss'\n",
    "\n",
    "pipe = Pipeline([('modelo', RandomForestClassifier(criterion=criterion,n_estimators=n_estimators,max_features=max_features,class_weight='balanced',max_depth=max_depth))])\n",
    "\n",
    "sampler = SMOTE()\n",
    "X_trans,y_trans = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "search = cross_validate(pipe, X_trans, y_trans, scoring=my_scorer_m, cv=5, return_estimator=True,return_train_score=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "y_pred_test = bests.predict_proba(X_test)[:,1]\n",
    "y_pred_train = bests.predict_proba(X_train)[:,1]\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations for RandomForest\n",
    "data = pd.read_csv(\"dados_hospital.csv\", sep=',')\n",
    "data.dropna(inplace=True)\n",
    "target = 'no_show'\n",
    "mapeamento = {'SIM': 0, 'NÃO': 1}\n",
    "data[target] = data[target].map(mapeamento).astype(int)\n",
    "data = data[data[\"distance\"]<1000]\n",
    "original_columns = list(data.columns[:-1])\n",
    "categoricalvar = {cl:data[cl].dtypes == np.object0 for cl in original_columns} \n",
    "categs = categorizar(data=data,columns=[cl for cl in original_columns if not categoricalvar[cl]])\n",
    "data = categs[\"data\"]\n",
    "\n",
    "encodar = [cl for cl in original_columns if categoricalvar[cl]]+[f\"{cl}_cat\" for cl in original_columns if not categoricalvar[cl]]\n",
    "encodado = meu_enconder(data=data,columns=encodar,target=target,split=False)\n",
    "\n",
    "data = encodado[\"data\"]\n",
    "res = significancia(data,categoricalvar,target)\n",
    "predictors = res[\"significantes\"]\n",
    "\n",
    "n_est = [9,15,25,55,75]\n",
    "max_features = [\"log2\",\"sqrt\"]\n",
    "max_depth = [2,3,5]\n",
    "crit = ['log_loss']\n",
    "\n",
    "combinations = list(product(n_est, max_depth,max_features,crit))\n",
    "\n",
    "simulacoes =  pd.DataFrame()\n",
    "for k,v in enumerate(combinations):\n",
    "    print(f\"modelo {k+1} de {len(combinations)}\")\n",
    "    pipe = Pipeline([('modelo', RandomForestClassifier(criterion=v[3],n_estimators=v[0],max_features=v[2],class_weight='balanced',max_depth=v[1]))])\n",
    "    res = simulador(pipe,data,predictors,target,50)\n",
    "    simulacoes[f\"sim_{k+1}\"] = res[\"geo_score\"]\n",
    "\n",
    "analise_sim = minha_anova(simulacoes.to_numpy().T,alpha=0.05)\n",
    "\n",
    "data_train,data_test = train_test_split(data,test_size=0.2, stratify=data[target])\n",
    "X_train,y_train = data_train[predictors],data_train[target]\n",
    "X_test,y_test = data_test[predictors],data_test[target]\n",
    "my_scorer,my_scorer_m = make_scorer(roc_auc_score,greater_is_better=True), make_scorer(minha_metrica,greater_is_better=True)\n",
    "\n",
    "\n",
    "idx = simulacoes.median().argmax()\n",
    "esc = analise_sim[\"stats\"][idx][\"igual_idx\"][0]\n",
    "v = combinations[esc]\n",
    "pipe = Pipeline([('modelo', RandomForestClassifier(criterion=v[3],n_estimators=v[0],max_features=v[2],class_weight='balanced',max_depth=v[1]))])\n",
    "search = cross_validate(pipe, X_train, y_train, scoring=my_scorer, cv=7, return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "y_pred_test = bests.predict_proba(X_test)[:,1]\n",
    "y_pred_train = bests.predict_proba(X_train)[:,1]\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations for KNN\n",
    "data = pd.read_csv(\"dados_hospital.csv\", sep=',')\n",
    "data.dropna(inplace=True)\n",
    "target = 'no_show'\n",
    "mapeamento = {'SIM': 0, 'NÃO': 1}\n",
    "data[target] = data[target].map(mapeamento).astype(int)\n",
    "data = data[data[\"distance\"]<1000]\n",
    "original_columns = list(data.columns[:-1])\n",
    "categoricalvar = {cl:data[cl].dtypes == np.object0 for cl in original_columns} \n",
    "categs = categorizar(data=data,columns=[cl for cl in original_columns if not categoricalvar[cl]])\n",
    "data = categs[\"data\"]\n",
    "\n",
    "encodar = [cl for cl in original_columns if categoricalvar[cl]]+[f\"{cl}_cat\" for cl in original_columns if not categoricalvar[cl]]\n",
    "encodado = meu_enconder(data=data,columns=encodar,target=target,split=False)\n",
    "\n",
    "data = encodado[\"data\"]\n",
    "res = significancia(data,categoricalvar,target)\n",
    "predictors = res[\"significantes\"]\n",
    "\n",
    "viz = list(range(40,141,10))\n",
    "pesos = [\"uniform\"]\n",
    "escalas = [MinMaxScaler(),StandardScaler()]\n",
    "\n",
    "combinations = list(product(viz,pesos,escalas))\n",
    "\n",
    "simulacoes =  pd.DataFrame()\n",
    "for k,v in enumerate(combinations):\n",
    "    print(f\"modelo {k+1} de {len(combinations)}\")\n",
    "    pipe = Pipeline([('escala',v[2]),('modelo', KNeighborsClassifier(n_neighbors=v[0],weights=v[1]))])\n",
    "    res = simulador(pipe,data,predictors,target,50)\n",
    "    simulacoes[f\"sim_{k+1}\"] = res[\"geo_score\"]\n",
    "\n",
    "analise_sim = minha_anova(simulacoes.to_numpy().T,alpha=0.05)\n",
    "\n",
    "data_train,data_test = train_test_split(data,test_size=0.2, stratify=data[target])\n",
    "X_train,y_train = data_train[predictors],data_train[target]\n",
    "X_test,y_test = data_test[predictors],data_test[target]\n",
    "my_scorer,my_scorer_m = make_scorer(roc_auc_score,greater_is_better=True), make_scorer(minha_metrica,greater_is_better=True)\n",
    "\n",
    "\n",
    "idx = simulacoes.mean().argmax()\n",
    "esc = analise_sim[\"stats\"][idx][\"igual_idx\"][0]\n",
    "v = combinations[esc]\n",
    "\n",
    "pipe = Pipeline([('escala',v[2]),('modelo', KNeighborsClassifier(n_neighbors=v[0],weights=v[1]))])\n",
    "\n",
    "search = cross_validate(pipe, X_train, y_train, scoring=my_scorer, cv=3, return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "# bests = pipe.fit(X_train, y_train)\n",
    "\n",
    "# coeficientes = pd.DataFrame({\"variável\":pipe.named_steps[\"poly\"].get_feature_names_out().ravel,\"coeficientes\":bests.named_steps[\"modelo\"].coef_.ravel()})\n",
    "# print(f\"{coeficientes}\\n\")\n",
    "\n",
    "y_pred_test = bests.predict_proba(X_test)[:,1]\n",
    "y_pred_train = bests.predict_proba(X_train)[:,1]\n",
    "\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations for Logistic Regression\n",
    "data = pd.read_csv(\"dados_hospital.csv\", sep=',')\n",
    "data.dropna(inplace=True)\n",
    "target = 'no_show'\n",
    "mapeamento = {'SIM': 0, 'NÃO': 1}\n",
    "data[target] = data[target].map(mapeamento).astype(int)\n",
    "data = data[data[\"distance\"]<1000]\n",
    "original_columns = list(data.columns[:-1])\n",
    "categoricalvar = {cl:data[cl].dtypes == np.object0 for cl in original_columns} \n",
    "categs = categorizar(data=data,columns=[cl for cl in original_columns if not categoricalvar[cl]])\n",
    "data = categs[\"data\"]\n",
    "\n",
    "encodar = [cl for cl in original_columns if categoricalvar[cl]]+[f\"{cl}_cat\" for cl in original_columns if not categoricalvar[cl]]\n",
    "encodado = meu_enconder(data=data,columns=encodar,target=target,split=False)\n",
    "\n",
    "data = encodado[\"data\"]\n",
    "res = significancia(data,categoricalvar,target)\n",
    "predictors = res[\"significantes\"]\n",
    "\n",
    "from itertools import product\n",
    "grau = [1,2]\n",
    "escala = [MinMaxScaler(),StandardScaler()]\n",
    "# regu = [10**(-i) for i in range(-1,20,3)]\n",
    "regu = [50,10,1, 0.1, 0.01, 0.001]\n",
    "regu = np.geomspace(0.01,10,20)\n",
    "\n",
    "combinations = list(product(grau, escala,regu))\n",
    "\n",
    "simulacoes =  pd.DataFrame()\n",
    "for k,v in enumerate(combinations):\n",
    "    print(f\"modelo {k+1} de {len(combinations)} \",end='\\r')\n",
    "    pipe = Pipeline([('poly',PolynomialFeatures(v[0])),('escala',v[1]),('modelo', LogisticRegression(penalty='l2',C = v[2],class_weight='balanced',max_iter=1000000))])\n",
    "    res = simulador_2(pipe,data,predictors,categoricalvar,target,50)\n",
    "    simulacoes[f\"sim_{k+1}\"] = res[\"geo_score\"]\n",
    "\n",
    "analise_sim = minha_anova(simulacoes.to_numpy().T,alpha=0.05)\n",
    "\n",
    "data_train,data_test = train_test_split(data,test_size=0.2, stratify=data[target])\n",
    "X_train,y_train = data_train[predictors],data_train[target]\n",
    "X_test,y_test = data_test[predictors],data_test[target]\n",
    "my_scorer,my_scorer_m = make_scorer(roc_auc_score,greater_is_better=True), make_scorer(geo_score,greater_is_better=True)\n",
    "\n",
    "\n",
    "idx = simulacoes.median().argmax()\n",
    "esc = analise_sim[\"stats\"][idx][\"igual_idx\"][0]\n",
    "v = combinations[esc]\n",
    "pipe = Pipeline([('poly',PolynomialFeatures(v[0])),('escala',v[1]),('modelo', LogisticRegression(penalty='l2',C = v[2],class_weight='balanced',max_iter=1000000))])\n",
    "search = cross_validate(pipe, X_train, y_train, scoring = my_scorer, cv = StratifiedKFold(5) , return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "y_pred_test = bests.predict_proba(X_test)[:,1]\n",
    "y_pred_train = bests.predict_proba(X_train)[:,1]\n",
    "\n",
    "salvarpipes(\"reg_linear\",bests,\"pipe_paramns\")\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulacoes para o KNN\n",
    "data = pd.read_csv(\"dados_hospital.csv\", sep=',')\n",
    "data.dropna(inplace=True)\n",
    "target = 'no_show'\n",
    "mapeamento = {'SIM': 0, 'NÃO': 1}\n",
    "data[target] = data[target].map(mapeamento).astype(int)\n",
    "data = data[data[\"distance\"]<1000]\n",
    "original_columns = list(data.columns[:-1])\n",
    "categoricalvar = {cl:data[cl].dtypes == np.object0 for cl in original_columns} \n",
    "categs = categorizar(data=data,columns=[cl for cl in original_columns if not categoricalvar[cl]])\n",
    "data = categs[\"data\"]\n",
    "\n",
    "encodar = [cl for cl in original_columns if categoricalvar[cl]]+[f\"{cl}_cat\" for cl in original_columns if not categoricalvar[cl]]\n",
    "encodado = meu_enconder(data=data,columns=encodar,target=target,split=False)\n",
    "\n",
    "data = encodado[\"data\"]\n",
    "res = significancia(data,categoricalvar,target)\n",
    "predictors = res[\"significantes\"]\n",
    "\n",
    "viz = list(range(40,141,10))\n",
    "pesos = [\"uniform\",\"distance\"]\n",
    "escalas = [MinMaxScaler(),StandardScaler()]\n",
    "\n",
    "combinations = list(product(viz,pesos,escalas))\n",
    "\n",
    "\n",
    "\n",
    "simulacoes =  pd.DataFrame()\n",
    "for k,v in enumerate(combinations):\n",
    "    print(f\"modelo {k+1} de {len(combinations)} \",end='\\r')\n",
    "    pipe = Pipeline([('escala',v[2]),('modelo', KNeighborsClassifier(n_neighbors=v[0],weights=v[1]))])\n",
    "    res = simulador_2(pipe,data,predictors,target,categoricalvar,50)\n",
    "    simulacoes[f\"sim_{k+1}\"] = res[\"geo_score\"]\n",
    "\n",
    "analise_sim = minha_anova(simulacoes.to_numpy().T,alpha=0.05)\n",
    "\n",
    "data_train,data_test = train_test_split(data,test_size=0.2, stratify=data[target])\n",
    "X_train,y_train = data_train[predictors],data_train[target]\n",
    "X_test,y_test = data_test[predictors],data_test[target]\n",
    "my_scorer,my_scorer_m = make_scorer(roc_auc_score,greater_is_better=True), make_scorer(geo_score,greater_is_better=True)\n",
    "\n",
    "\n",
    "idx = simulacoes.median().argmax()\n",
    "esc = analise_sim[\"stats\"][idx][\"igual_idx\"][0]\n",
    "v = combinations[esc]\n",
    "pipe = Pipeline([('escala',v[2]),('modelo', KNeighborsClassifier(n_neighbors=v[0],weights=v[1]))])\n",
    "search = cross_validate(pipe, X_train, y_train, scoring = my_scorer, cv = StratifiedKFold(5) , return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "y_pred_test = predicao(bests,X_test)\n",
    "y_pred_train = predicao(bests,X_train)\n",
    "\n",
    "salvarpipes(\"knn\",bests,\"pipe_paramns\")\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulacoes para o Random Forest\n",
    "data = pd.read_csv(\"dados_hospital.csv\", sep=',')\n",
    "data.dropna(inplace=True)\n",
    "target = 'no_show'\n",
    "mapeamento = {'SIM': 0, 'NÃO': 1}\n",
    "data[target] = data[target].map(mapeamento).astype(int)\n",
    "data = data[data[\"distance\"]<1000]\n",
    "original_columns = list(data.columns[:-1])\n",
    "categoricalvar = {cl:data[cl].dtypes == np.object0 for cl in original_columns} \n",
    "categs = categorizar(data=data,columns=[cl for cl in original_columns if not categoricalvar[cl]])\n",
    "data = categs[\"data\"]\n",
    "\n",
    "encodar = [cl for cl in original_columns if categoricalvar[cl]]+[f\"{cl}_cat\" for cl in original_columns if not categoricalvar[cl]]\n",
    "encodado = meu_enconder(data=data,columns=encodar,target=target,split=False)\n",
    "\n",
    "data = encodado[\"data\"]\n",
    "res = significancia(data,categoricalvar,target)\n",
    "predictors = res[\"significantes\"]\n",
    "\n",
    "n_est = [9,15,25,55,75]\n",
    "max_features = [\"log2\",\"sqrt\"]\n",
    "max_depth = [1,2,3,4]\n",
    "crit = [\"gini\", \"entropy\",'log_loss']\n",
    "\n",
    "combinations = list(product(n_est, max_depth,max_features,crit))\n",
    "\n",
    "\n",
    "simulacoes =  pd.DataFrame()\n",
    "for k,v in enumerate(combinations):\n",
    "    print(f\"modelo {k+1} de {len(combinations)} \",end='\\r')\n",
    "    pipe = Pipeline([('modelo', RandomForestClassifier(criterion=v[3],n_estimators=v[0],max_features=v[2],class_weight='balanced',max_depth=v[1]))])\n",
    "    res = simulador_2(pipe,data,predictors,target,categoricalvar,50)\n",
    "    simulacoes[f\"sim_{k+1}\"] = res[\"geo_score\"]\n",
    "\n",
    "analise_sim = minha_anova(simulacoes.to_numpy().T,alpha=0.05)\n",
    "\n",
    "data_train,data_test = train_test_split(data,test_size=0.2, stratify=data[target])\n",
    "X_train,y_train = data_train[predictors],data_train[target]\n",
    "X_test,y_test = data_test[predictors],data_test[target]\n",
    "my_scorer,my_scorer_m = make_scorer(roc_auc_score,greater_is_better=True), make_scorer(geo_score,greater_is_better=True)\n",
    "\n",
    "\n",
    "idx = simulacoes.median().argmax()\n",
    "esc = analise_sim[\"stats\"][idx][\"igual_idx\"][0]\n",
    "v = combinations[esc]\n",
    "pipe = Pipeline([('modelo', RandomForestClassifier(criterion=v[3],n_estimators=v[0],max_features=v[2],class_weight='balanced',max_depth=v[1]))])\n",
    "search = cross_validate(pipe, X_train, y_train, scoring = my_scorer, cv = StratifiedKFold(5) , return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "y_pred_test = predicao(bests,X_test)\n",
    "y_pred_train = predicao(bests,X_train)\n",
    "\n",
    "salvarpipes(\"random_forest\",bests,\"pipe_paramns\")\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulacoes para o SGD Classifier\n",
    "data = pd.read_csv(\"dados_hospital.csv\", sep=',')\n",
    "data.dropna(inplace=True)\n",
    "target = 'no_show'\n",
    "mapeamento = {'SIM': 0, 'NÃO': 1}\n",
    "data[target] = data[target].map(mapeamento).astype(int)\n",
    "data = data[data[\"distance\"]<1000]\n",
    "original_columns = list(data.columns[:-1])\n",
    "categoricalvar = {cl:data[cl].dtypes == np.object0 for cl in original_columns} \n",
    "categs = categorizar(data=data,columns=[cl for cl in original_columns if not categoricalvar[cl]])\n",
    "data = categs[\"data\"]\n",
    "\n",
    "encodar = [cl for cl in original_columns if categoricalvar[cl]]+[f\"{cl}_cat\" for cl in original_columns if not categoricalvar[cl]]\n",
    "encodado = meu_enconder(data=data,columns=encodar,target=target,split=False)\n",
    "\n",
    "data = encodado[\"data\"]\n",
    "res = significancia(data,categoricalvar,target)\n",
    "predictors = res[\"significantes\"]\n",
    "\n",
    "escala = [MinMaxScaler(),StandardScaler()]\n",
    "regu = np.geomspace(0.01,1,5)\n",
    "lossfct = [\"hinge\", \"log_loss\", \"log\", \"modified_huber\", \"squared_hinge\", \"huber\"]\n",
    "penalti = [\"l1\",\"l2\"]\n",
    "\n",
    "combinations = list(product(escala,regu,lossfct,penalti))\n",
    "\n",
    "simulacoes =  pd.DataFrame()\n",
    "for k,v in enumerate(combinations):\n",
    "    print(f\"modelo {k+1} de {len(combinations)} \",end='\\r')\n",
    "    pipe = Pipeline([('escala',v[0]),('modelo', SGDClassifier(loss=v[2],penalty=v[3],class_weight='balanced',alpha = v[1],max_iter=10000))])\n",
    "    res = simulador_2(pipe,data,predictors,target,categoricalvar,50)\n",
    "    simulacoes[f\"sim_{k+1}\"] = res[\"geo_score\"]\n",
    "\n",
    "analise_sim = minha_anova(simulacoes.to_numpy().T,alpha=0.05)\n",
    "\n",
    "data_train,data_test = train_test_split(data,test_size=0.2, stratify=data[target])\n",
    "X_train,y_train = data_train[predictors],data_train[target]\n",
    "X_test,y_test = data_test[predictors],data_test[target]\n",
    "my_scorer,my_scorer_m = make_scorer(roc_auc_score,greater_is_better=True), make_scorer(geo_score,greater_is_better=True)\n",
    "\n",
    "\n",
    "idx = simulacoes.median().argmax()\n",
    "esc = analise_sim[\"stats\"][idx][\"igual_idx\"][0]\n",
    "v = combinations[esc]\n",
    "pipe = Pipeline([('escala',v[0]),('modelo', SGDClassifier(loss=v[2],penalty=v[3],class_weight='balanced',alpha = v[1],max_iter=10000))])\n",
    "search = cross_validate(pipe, X_train, y_train, scoring = my_scorer, cv = StratifiedKFold(5) , return_estimator=True)\n",
    "bests = search['estimator'][np.argmax(search['test_score'])]\n",
    "\n",
    "y_pred_test = predicao(bests,X_test)\n",
    "y_pred_train = predicao(bests,X_train)\n",
    "\n",
    "salvarpipes(\"sgd\",bests,\"pipe_paramns\")\n",
    "\n",
    "res = get_scores(y_train,y_pred_train,y_test,y_pred_test,scorers=[minha_metrica_c,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score])\n",
    "print(f\"{res['metricas']}\\n\")\n",
    "print(f\"{res['confusion_matrix']}\\n\")\n",
    "curva_test = res[\"roc_curve_test\"]\n",
    "curva_train = res[\"roc_curve_train\"]\n",
    "melhor = res[\"melhor\"]\n",
    "plt.plot(curva_train[\"fpr\"], curva_train[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot(curva_test[\"fpr\"], curva_test[\"tpr\"], label='ROC Curve - train')\n",
    "plt.plot([0, 1], [0, 1], color = 'k', ls = 'dashed', label='Random classifier')\n",
    "plt.scatter(melhor[0],melhor[1],label='Best Classifier',color = 'red')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = analise_sim[\"stats\"][idx][\"igual_idx\"]\n",
    "simulacoes[[f\"sim_{i+1}\" for i in [esc,idx]]].plot.box()\n",
    "[combinations[i] for i in [esc,idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corte = res[\"melhor\"][2]\n",
    "agrupado = agrupa_predicoes(bests,data_train,data_test,predictors,target,categoricalvar,corte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests.named_steps[\"modelo\"].__init__()\n",
    "# json.dumps(bests.named_steps[\"modelo\"].__str__().split(\"(\")[0])\n",
    "# json.dumps(bests.named_steps[\"modelo\"].get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(bests.named_steps[\"modelo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salvarpipes(\"sgd\",bests,\"pipe_paramns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pipe_paramns\", 'r') as file:\n",
    "     existing_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_data[\"sgd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests.named_steps[\"modelo\"].base_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests.named_steps[\"modelo\"].get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
