{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import seaborn as sns, pandas as pd, numpy as np\n",
    "\n",
    "data = pd.read_csv(\"dados_classificacao/dados.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import seaborn as sns, pandas as pd, numpy as np\n",
    "\n",
    "data = pd.read_csv(\"dados_classificacao/dados_hospital.csv\", sep=',')\n",
    "\n",
    "# renomear = ['gender','age','race','marital_status','schooling','city','distance','cancer','day','shift','month','season','lead_time','no_cons_scheduled_previous_year','no_ns_cons_previous_year','no_exa_scheduled_previous_year','no_ns_exa_previous_year','no_show'] \n",
    "# mapeamento = {coluna: renomear[i] for i, coluna in enumerate(data.columns)}\n",
    "# # # # Renomear as colunas com o mapeamento\n",
    "# data.rename(columns=mapeamento, inplace=True)\n",
    "# data.drop(['city','season'],axis=1,inplace=True)\n",
    "# data.to_csv(\"dados_classificacao/dados_hospital.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>schooling</th>\n",
       "      <th>distance</th>\n",
       "      <th>cancer</th>\n",
       "      <th>day</th>\n",
       "      <th>shift</th>\n",
       "      <th>month</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>no_cons_scheduled_previous_year</th>\n",
       "      <th>no_ns_cons_previous_year</th>\n",
       "      <th>no_exa_scheduled_previous_year</th>\n",
       "      <th>no_ns_exa_previous_year</th>\n",
       "      <th>no_show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>77</td>\n",
       "      <td>BRANCA</td>\n",
       "      <td>CASADO</td>\n",
       "      <td>1O GRAU COMPLETO</td>\n",
       "      <td>1</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>QUARTA-FEIRA</td>\n",
       "      <td>MANHÃ - 00:00:00 A 11:59:59</td>\n",
       "      <td>SETEMBRO</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>BRANCA</td>\n",
       "      <td>SOLTEIRO</td>\n",
       "      <td>SUPERIOR INCOMPLETO</td>\n",
       "      <td>1</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>SEXTA-FEIRA</td>\n",
       "      <td>TARDE - 12:00:00 A 23:59:59</td>\n",
       "      <td>NOVEMBRO</td>\n",
       "      <td>478</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>87</td>\n",
       "      <td>BRANCA</td>\n",
       "      <td>CASADO</td>\n",
       "      <td>2O GRAU COMPLETO</td>\n",
       "      <td>1</td>\n",
       "      <td>SIM</td>\n",
       "      <td>SEGUNDA-FEIRA</td>\n",
       "      <td>MANHÃ - 00:00:00 A 11:59:59</td>\n",
       "      <td>SETEMBRO</td>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>83</td>\n",
       "      <td>BRANCA</td>\n",
       "      <td>CASADO</td>\n",
       "      <td>2O GRAU COMPLETO</td>\n",
       "      <td>1</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>SEXTA-FEIRA</td>\n",
       "      <td>MANHÃ - 00:00:00 A 11:59:59</td>\n",
       "      <td>SETEMBRO</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>50</td>\n",
       "      <td>BRANCA</td>\n",
       "      <td>SOLTEIRO</td>\n",
       "      <td>1O GRAU INCOMPLETO</td>\n",
       "      <td>290</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>SEGUNDA-FEIRA</td>\n",
       "      <td>MANHÃ - 00:00:00 A 11:59:59</td>\n",
       "      <td>NOVEMBRO</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  age    race marital_status            schooling  distance cancer  \\\n",
       "0      F   77  BRANCA         CASADO     1O GRAU COMPLETO         1    NÃO   \n",
       "1      F   46  BRANCA       SOLTEIRO  SUPERIOR INCOMPLETO         1    NÃO   \n",
       "2      F   87  BRANCA         CASADO     2O GRAU COMPLETO         1    SIM   \n",
       "3      F   83  BRANCA         CASADO     2O GRAU COMPLETO         1    NÃO   \n",
       "4      F   50  BRANCA       SOLTEIRO   1O GRAU INCOMPLETO       290    NÃO   \n",
       "\n",
       "             day                        shift     month  lead_time  \\\n",
       "0   QUARTA-FEIRA  MANHÃ - 00:00:00 A 11:59:59  SETEMBRO          6   \n",
       "1    SEXTA-FEIRA  TARDE - 12:00:00 A 23:59:59  NOVEMBRO        478   \n",
       "2  SEGUNDA-FEIRA  MANHÃ - 00:00:00 A 11:59:59  SETEMBRO        195   \n",
       "3    SEXTA-FEIRA  MANHÃ - 00:00:00 A 11:59:59  SETEMBRO          6   \n",
       "4  SEGUNDA-FEIRA  MANHÃ - 00:00:00 A 11:59:59  NOVEMBRO         27   \n",
       "\n",
       "   no_cons_scheduled_previous_year  no_ns_cons_previous_year  \\\n",
       "0                                1                         0   \n",
       "1                               48                        13   \n",
       "2                                3                         0   \n",
       "3                               17                         1   \n",
       "4                                7                         3   \n",
       "\n",
       "   no_exa_scheduled_previous_year  no_ns_exa_previous_year no_show  \n",
       "0                               0                        0     SIM  \n",
       "1                               8                        0     SIM  \n",
       "2                               1                        0     SIM  \n",
       "3                               2                        0     SIM  \n",
       "4                               0                        0     SIM  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object    9\n",
       "int64     7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "le = LabelEncoder()\n",
    "for cl in data.columns:\n",
    "    if data[cl].dtypes==np.object0:\n",
    "        data[cl] = le.fit_transform(data[cl])\n",
    "\n",
    "data.dtypes.value_counts()\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# encoder = OneHotEncoder(sparse=False)\n",
    "# encoded_data = encoder.fit_transform(data[categorical_cols])\n",
    "\n",
    "# encoded_df = pd.concat([data.drop(categorical_cols, axis=1),\n",
    "#                         pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))],\n",
    "#                        axis=1)\n",
    "# data = encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8382 entries, 0 to 8381\n",
      "Data columns (total 16 columns):\n",
      " #   Column                           Non-Null Count  Dtype\n",
      "---  ------                           --------------  -----\n",
      " 0   gender                           8382 non-null   int64\n",
      " 1   age                              8382 non-null   int64\n",
      " 2   race                             8382 non-null   int64\n",
      " 3   marital_status                   8382 non-null   int64\n",
      " 4   schooling                        8382 non-null   int64\n",
      " 5   distance                         8382 non-null   int64\n",
      " 6   cancer                           8382 non-null   int64\n",
      " 7   day                              8382 non-null   int64\n",
      " 8   shift                            8382 non-null   int64\n",
      " 9   month                            8382 non-null   int64\n",
      " 10  lead_time                        8382 non-null   int64\n",
      " 11  no_cons_scheduled_previous_year  8382 non-null   int64\n",
      " 12  no_ns_cons_previous_year         8382 non-null   int64\n",
      " 13  no_exa_scheduled_previous_year   8382 non-null   int64\n",
      " 14  no_ns_exa_previous_year          8382 non-null   int64\n",
      " 15  no_show                          8382 non-null   int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>schooling</th>\n",
       "      <th>distance</th>\n",
       "      <th>cancer</th>\n",
       "      <th>day</th>\n",
       "      <th>shift</th>\n",
       "      <th>month</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>no_cons_scheduled_previous_year</th>\n",
       "      <th>no_ns_cons_previous_year</th>\n",
       "      <th>no_exa_scheduled_previous_year</th>\n",
       "      <th>no_ns_exa_previous_year</th>\n",
       "      <th>no_show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>478</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age  race  marital_status  schooling  distance  cancer  day  shift  \\\n",
       "0       0   77     1               0          0         1       0    1      0   \n",
       "1       0   46     1               4          6         1       0    4      1   \n",
       "2       0   87     1               0          2         1       1    3      0   \n",
       "3       0   83     1               0          2         1       0    4      0   \n",
       "4       0   50     1               4          1       290       0    3      0   \n",
       "\n",
       "   month  lead_time  no_cons_scheduled_previous_year  \\\n",
       "0     11          6                                1   \n",
       "1      9        478                               48   \n",
       "2     11        195                                3   \n",
       "3     11          6                               17   \n",
       "4      9         27                                7   \n",
       "\n",
       "   no_ns_cons_previous_year  no_exa_scheduled_previous_year  \\\n",
       "0                         0                               0   \n",
       "1                        13                               8   \n",
       "2                         0                               1   \n",
       "3                         1                               2   \n",
       "4                         3                               0   \n",
       "\n",
       "   no_ns_exa_previous_year  no_show  \n",
       "0                        0        1  \n",
       "1                        0        1  \n",
       "2                        0        1  \n",
       "3                        0        1  \n",
       "4                        0        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'no_show'\n",
    "X = data.drop([target,'cancer'], axis=1)\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "contingency_table = pd.crosstab(data['race'], data['no_show'])\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(\"Estatística de Teste Chi-Quadrado:\", chi2)\n",
    "print(\"Valor p:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, f_oneway\n",
    "# data[\"a2\"] = data.age*1\n",
    "grouped = data.groupby('no_show')\n",
    "# Realizar o teste t de Student para cada grupo\n",
    "group1 = grouped.get_group(1)['distance']\n",
    "group2 = grouped.get_group(0)['distance']\n",
    "t_statistic, p_value = ttest_ind(group1, group2)\n",
    "# Imprimir os resultados\n",
    "print(\"Estatística t:\", t_statistic)\n",
    "print(\"Valor p:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group1.mean(),group1.std(),group2.mean(),group2.std(),len(group1),len(group2)\n",
    "percentiles = np.linspace(1e-10,1.0-1.e-10,10)\n",
    "variable = 'no_exa_scheduled_previous_year'\n",
    "results = {}\n",
    "for percentile in percentiles:\n",
    "    # Calcular o valor do percentil para a coluna 'age'\n",
    "    age_percentile = data[variable].quantile(percentile)\n",
    "    \n",
    "    # Filtrar o DataFrame com base no percentil\n",
    "    filtered_df = data[data[variable] <= age_percentile]\n",
    "    \n",
    "    # Calcular a proporção de 'no_show' no subconjunto filtrado\n",
    "    no_show_proportion = filtered_df['no_show'].value_counts(normalize=True)\n",
    "    \n",
    "    # Armazenar a proporção no dicionário de resultados\n",
    "    results[age_percentile] = no_show_proportion\n",
    "\n",
    "# Criar um DataFrame a partir do dicionário de resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(\"Proporções de 'no_show' para os percentis:\")\n",
    "results_df\n",
    "results_df.loc[0,:].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = list(data.columns)\n",
    "sns.set(style = 'ticks', color_codes=True)\n",
    "sns.pairplot(data=data, vars = data[[variables[i] for i in [1,5,10]]] , hue = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=data, x='no_show')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(data= data.corr(), annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,2, figsize=(16,16))\n",
    "sns.distplot(data.var_1, bins = 20, ax=ax[0,0]) \n",
    "sns.distplot(data.var_2, bins = 20, ax=ax[0,1]) \n",
    "sns.distplot(data.var_3, bins = 20, ax=ax[1,0]) \n",
    "sns.distplot(data.var_4, bins = 20, ax=ax[1,1]) \n",
    "sns.distplot(data.var_5, bins = 20, ax=ax[2,0])\n",
    "sns.distplot(data.var_6, bins = 20, ax=ax[2,1])\n",
    "sns.distplot(data.var_7, bins = 20, ax=ax[3,0]) \n",
    "sns.distplot(data.var_8, bins = 20, ax=ax[3,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlations = X.corrwith(y)\n",
    "correlations.sort_values(inplace=True)\n",
    "correlations\n",
    "ax = correlations.plot(kind='bar')\n",
    "ax.set(ylim=[-.1, 0.1], ylabel='pearson correlation')\n",
    "\n",
    "# X.corrwith(data.COMPARECEU_AGENDAMENTO_EXAME).plot.bar(figsize = (15, 10), title = \"Correlation with Target\", fontsize = 10,grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=data.ESTACAO_AGENDAMENTO,y=y,hue=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation Matrix\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = data.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6705 entries, 4589 to 2876\n",
      "Data columns (total 14 columns):\n",
      " #   Column                           Non-Null Count  Dtype\n",
      "---  ------                           --------------  -----\n",
      " 0   gender                           6705 non-null   int64\n",
      " 1   age                              6705 non-null   int64\n",
      " 2   race                             6705 non-null   int64\n",
      " 3   marital_status                   6705 non-null   int64\n",
      " 4   schooling                        6705 non-null   int64\n",
      " 5   distance                         6705 non-null   int64\n",
      " 6   day                              6705 non-null   int64\n",
      " 7   shift                            6705 non-null   int64\n",
      " 8   month                            6705 non-null   int64\n",
      " 9   lead_time                        6705 non-null   int64\n",
      " 10  no_cons_scheduled_previous_year  6705 non-null   int64\n",
      " 11  no_ns_cons_previous_year         6705 non-null   int64\n",
      " 12  no_exa_scheduled_previous_year   6705 non-null   int64\n",
      " 13  no_ns_exa_previous_year          6705 non-null   int64\n",
      "dtypes: int64(14)\n",
      "memory usage: 785.7 KB\n"
     ]
    }
   ],
   "source": [
    "X_tt= pd.DataFrame(X_train,columns=X.columns)\n",
    "X_tt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "classifier = LogisticRegression(random_state=0, penalty='l2')\n",
    "classifier.fit(X_train, y_train)\n",
    "zz = classifier.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18202083, 0.03716733, 0.05479497, ..., 0.05919521, 0.06680544,\n",
       "       0.05209738])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m my_scorer \u001b[39m=\u001b[39m make_scorer(minha_metrica,greater_is_better\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,needs_proba\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m piplr \u001b[39m=\u001b[39m Pipeline([(\u001b[39m'\u001b[39m\u001b[39mescala\u001b[39m\u001b[39m'\u001b[39m,StandardScaler()),(\u001b[39m'\u001b[39m\u001b[39mmodelo\u001b[39m\u001b[39m'\u001b[39m, LogisticRegression(penalty\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m))])\n\u001b[0;32m---> 30\u001b[0m cvr \u001b[39m=\u001b[39m cross_validate(piplr,X_train, y_train,scoring \u001b[39m=\u001b[39;49m minha_metrica, cv\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,return_estimator\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, error_score\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mraise\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     31\u001b[0m cvr[\u001b[39m'\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    705\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    707\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m--> 708\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[1;32m    709\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[1;32m    710\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    765\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[1;32m    766\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[1;32m    768\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m error_score \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "Cell \u001b[0;32mIn[65], line 11\u001b[0m, in \u001b[0;36mminha_metrica\u001b[0;34m(y_true, y_pred, zz)\u001b[0m\n\u001b[1;32m      8\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m0.05\u001b[39m  \u001b[39m# Defina o threshold desejado\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Calcule o true positive rate para o threshold dado\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred[:,\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     12\u001b[0m tp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum((y_true \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m (y_pred \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold))\n\u001b[1;32m     13\u001b[0m fn \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum((y_true \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m (y_pred \u001b[39m<\u001b[39m threshold))\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/pandas/core/indexes/base.py:3810\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3805\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3810\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/basico/lib/python3.10/site-packages/pandas/core/indexes/base.py:5968\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5964\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   5965\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5966\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5967\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5968\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer,f1_score,accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def minha_metrica(y_true, y_pred, zz):\n",
    "    threshold = 0.05  # Defina o threshold desejado\n",
    "\n",
    "    # Calcule o true positive rate para o threshold dado\n",
    "    y_pred = y_pred[:,0]\n",
    "    tp = np.sum((y_true == 1) & (y_pred >= threshold))\n",
    "    fn = np.sum((y_true == 1) & (y_pred < threshold))\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    # Calcule o true negative rate para o threshold dado\n",
    "    tn = np.sum((y_true == 0) & (y_pred < threshold))\n",
    "    fp = np.sum((y_true == 0) & (y_pred >= threshold))\n",
    "    tnr = tn / (tn + fp)\n",
    "\n",
    "    # Calcule o produto dos passos 1 e 2\n",
    "    product = tpr * tnr\n",
    "\n",
    "    # Retorne a raiz quadrada do passo 3\n",
    "    return np.sqrt(product)\n",
    "\n",
    "my_scorer = make_scorer(minha_metrica,greater_is_better=True,needs_proba=True)\n",
    "\n",
    "piplr = Pipeline([('escala',StandardScaler()),('modelo', LogisticRegression(penalty='l2'))])\n",
    "cvr = cross_validate(piplr,X_train, y_train,scoring = minha_metrica, cv=3,return_estimator=True, error_score=\"raise\")\n",
    "cvr['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = cvr['estimator']\n",
    "best_model = estimators[np.argmax(cvr['test_score'])]\n",
    "best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01434112, 0.01267791, 0.11358285]),\n",
       " 'score_time': array([0.00255108, 0.00219512, 0.00205803]),\n",
       " 'estimator': [Pipeline(steps=[('escala', StandardScaler()), ('modelo', LogisticRegression())]),\n",
       "  Pipeline(steps=[('escala', StandardScaler()), ('modelo', LogisticRegression())]),\n",
       "  Pipeline(steps=[('escala', StandardScaler()), ('modelo', LogisticRegression())])],\n",
       " 'test_score': array([0.93333333, 0.93333333, 0.93333333])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;escala&#x27;, StandardScaler()), (&#x27;modelo&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;escala&#x27;, StandardScaler()), (&#x27;modelo&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('escala', StandardScaler()), ('modelo', LogisticRegression())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score,recall_score,precision_score, confusion_matrix\n",
    "# classifier = LogisticRegression(penalty='l2')\n",
    "kf =  StratifiedKFold(n_splits=5)\n",
    "scr = []\n",
    "pipe = Pipeline([('escala',StandardScaler()),('modelo', LogisticRegression(penalty='l2'))])\n",
    "for train, test in kf.split(X,y):\n",
    "    Xtr,Xts = X.iloc[train,:],X.iloc[test,:]\n",
    "    ytr,yts = y[train],y[test]\n",
    "    pipe.fit(Xtr,ytr)\n",
    "    ypr = pipe.predict(Xts)\n",
    "    cm = confusion_matrix(yts,ypr,normalize='true')\n",
    "    scr.append(np.sqrt(cm[0][0]*cm[1][1]))\n",
    "    \n",
    "print(scr)\n",
    "    # classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score,recall_score,precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "kf =  StratifiedKFold(n_splits=5)\n",
    "scr = []\n",
    "poly = PolynomialFeatures(degree=5)\n",
    "pipe = Pipeline([(('poli',poly)),('escala',StandardScaler()),('modelo', LogisticRegression(penalty='l2'))])\n",
    "for train, test in kf.split(X,y):\n",
    "    Xtr,Xts = X.iloc[train,:],X.iloc[test,:]\n",
    "    ytr,yts = y[train],y[test]\n",
    "    pipe.fit(Xtr,ytr)\n",
    "    ypr = pipe.predict(Xts)\n",
    "    cm = confusion_matrix(yts,ypr,normalize='true')\n",
    "    # scr.append(np.sqrt(cm[0][0]*cm[1][1]))\n",
    "    scr.append(accuracy_score(yts,ypr))\n",
    "    \n",
    "print(scr)\n",
    "    # classifier.fit(X_train, y_train)\n",
    "\n",
    "# scr2 = cross_val_score(pipe,X,y,cv = 5)\n",
    "# print(scr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer,f1_score,accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def minha_metrica(y_true, y_pred):\n",
    "    threshold = 0.5  # Defina o threshold desejado\n",
    "    \n",
    "\n",
    "    # Calcule o true positive rate para o threshold dado\n",
    "    tp = np.sum((y_true == 1) & (y_pred >= threshold))\n",
    "    fn = np.sum((y_true == 1) & (y_pred < threshold))\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    # Calcule o true negative rate para o threshold dado\n",
    "    tn = np.sum((y_true == 0) & (y_pred < threshold))\n",
    "    fp = np.sum((y_true == 0) & (y_pred >= threshold))\n",
    "    tnr = tn / (tn + fp)\n",
    "\n",
    "    # Calcule o produto dos passos 1 e 2\n",
    "    product = tpr * tnr\n",
    "\n",
    "    # Retorne a raiz quadrada do passo 3\n",
    "    return np.sqrt(product)\n",
    "\n",
    "my_scorer = make_scorer(minha_metrica,greater_is_better=True)\n",
    "\n",
    "poly = PolynomialFeatures(degree=6)\n",
    "pipe = Pipeline([(('poli',poly)),('escala',StandardScaler()),('modelo', LogisticRegression(penalty='l2'))])\n",
    "cvr = cross_validate(pipe, X_train, y_train, cv=3, scoring=accuracy_score, return_estimator=True)\n",
    "cvr['test_score']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = cvr['estimator']\n",
    "best_model = estimators[np.argmax(cvr['test_score'])]\n",
    "# coefs = best_model.named_steps['modelo'].coef_[0]\n",
    "cvr['test_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, f1_score,recall_score,precision_score, confusion_matrix\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "results = pd.DataFrame([['Logistic Regression (Lasso)', acc,prec,rec,f1]],columns=['Model', 'Accuracy', 'Precision', 'Recall','F1 Score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = classifier.predict_proba(X_test)\n",
    "from scipy import integrate\n",
    "def capcurve(y_values, y_preds_proba):\n",
    "    num_pos_obs = np.sum(y_values)\n",
    "    num_count = len(y_values)\n",
    "    rate_pos_obs = float(num_pos_obs) / float(num_count)\n",
    "    ideal = pd.DataFrame({'x':[0,rate_pos_obs,1],'y':[0,1,1]})\n",
    "    xx = np.arange(num_count) / float(num_count - 1)\n",
    "    \n",
    "    y_cap = np.c_[y_values,y_preds_proba]\n",
    "    y_cap_df_s = pd.DataFrame(data=y_cap)\n",
    "    y_cap_df_s = y_cap_df_s.sort_values([1], ascending=False).reset_index(level = y_cap_df_s.index.names, drop=True)\n",
    "    \n",
    "    print(y_cap_df_s.head(20))\n",
    "    \n",
    "    yy = np.cumsum(y_cap_df_s[0]) / float(num_pos_obs)\n",
    "    yy = np.append([0], yy[0:num_count-1]) #add the first curve point (0,0) : for xx=0 we have yy=0\n",
    "    \n",
    "    percent = 0.5\n",
    "    row_index = int(np.trunc(num_count * percent))\n",
    "    \n",
    "    val_y1 = yy[row_index]\n",
    "    val_y2 = yy[row_index+1]\n",
    "    if val_y1 == val_y2:\n",
    "        val = val_y1*1.0\n",
    "    else:\n",
    "        val_x1 = xx[row_index]\n",
    "        val_x2 = xx[row_index+1]\n",
    "        val = val_y1 + ((val_x2 - percent)/(val_x2 - val_x1))*(val_y2 - val_y1)\n",
    "    \n",
    "    sigma_ideal = 1 * xx[num_pos_obs - 1 ] / 2 + (xx[num_count - 1] - xx[num_pos_obs]) * 1\n",
    "    sigma_model = integrate.simps(yy,xx)\n",
    "    sigma_random = integrate.simps(xx,xx)\n",
    "    \n",
    "    ar_value = (sigma_model - sigma_random) / (sigma_ideal - sigma_random)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 1)\n",
    "    ax.plot(ideal['x'],ideal['y'], color='grey', label='Perfect Model')\n",
    "    ax.plot(xx,yy, color='red', label='User Model')\n",
    "    ax.plot(xx,xx, color='blue', label='Random Model')\n",
    "    ax.plot([percent, percent], [0.0, val], color='green', linestyle='--', linewidth=1)\n",
    "    ax.plot([0, percent], [val, val], color='green', linestyle='--', linewidth=1, label=str(val*100)+'% of positive obs at '+str(percent*100)+'%')\n",
    "    \n",
    "    plt.xlim(0, 1.02)\n",
    "    plt.ylim(0, 1.25)\n",
    "    plt.title(\"CAP Curve - a_r value =\"+str(ar_value))\n",
    "    plt.xlabel('% of the data')\n",
    "    plt.ylabel('% of positive obs')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capcurve(y_test,y_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator= classifier, X=X_train, y=y_train, cv=10)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "print('Logistic Regression (Lasso) Accuracy: %0.3f (+/- %0.3f)' % (accuracies.mean(), accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_train.columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection \n",
    "#Recursive feature elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Select best feature \n",
    "rfe = RFE(classifier, n_features_to_select= None)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "#Summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Correlation Matrix\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = X_train[X_train.columns[rfe.support_]].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(18, 15))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0, penalty= 'l2')\n",
    "classifier.fit(X_train[X_train.columns[rfe.support_]], y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test[X_train.columns[rfe.support_]])\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Logistic Regression RFE (Lasso)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = classifier.predict_proba(X_test[X_train.columns[rfe.support_]])\n",
    "capcurve(y_test,y_pred_prob[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
