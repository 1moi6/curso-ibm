{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import seaborn as sns, pandas as pd, numpy as np\n",
    "\n",
    "data = pd.read_csv(\"dados_classificacao/dados.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import seaborn as sns, pandas as pd, numpy as np\n",
    "\n",
    "data = pd.read_csv(\"dados_classificacao/dados_hospital.csv\", sep=',')\n",
    "\n",
    "# renomear = ['gender','age','race','marital_status','schooling','city','distance','cancer','day','shift','month','season','lead_time','no_cons_scheduled_previous_year','no_ns_cons_previous_year','no_exa_scheduled_previous_year','no_ns_exa_previous_year','no_show'] \n",
    "# mapeamento = {coluna: renomear[i] for i, coluna in enumerate(data.columns)}\n",
    "# # # # Renomear as colunas com o mapeamento\n",
    "# data.rename(columns=mapeamento, inplace=True)\n",
    "# data.drop(['city','season'],axis=1,inplace=True)\n",
    "# data.to_csv(\"dados_classificacao/dados_hospital.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>schooling</th>\n",
       "      <th>distance</th>\n",
       "      <th>cancer</th>\n",
       "      <th>day</th>\n",
       "      <th>shift</th>\n",
       "      <th>month</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>no_cons_scheduled_previous_year</th>\n",
       "      <th>no_ns_cons_previous_year</th>\n",
       "      <th>no_exa_scheduled_previous_year</th>\n",
       "      <th>no_ns_exa_previous_year</th>\n",
       "      <th>no_show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>77</td>\n",
       "      <td>BRANCA</td>\n",
       "      <td>CASADO</td>\n",
       "      <td>1O GRAU COMPLETO</td>\n",
       "      <td>1</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>QUARTA-FEIRA</td>\n",
       "      <td>MANHÃ - 00:00:00 A 11:59:59</td>\n",
       "      <td>SETEMBRO</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>BRANCA</td>\n",
       "      <td>SOLTEIRO</td>\n",
       "      <td>SUPERIOR INCOMPLETO</td>\n",
       "      <td>1</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>SEXTA-FEIRA</td>\n",
       "      <td>TARDE - 12:00:00 A 23:59:59</td>\n",
       "      <td>NOVEMBRO</td>\n",
       "      <td>478</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>87</td>\n",
       "      <td>BRANCA</td>\n",
       "      <td>CASADO</td>\n",
       "      <td>2O GRAU COMPLETO</td>\n",
       "      <td>1</td>\n",
       "      <td>SIM</td>\n",
       "      <td>SEGUNDA-FEIRA</td>\n",
       "      <td>MANHÃ - 00:00:00 A 11:59:59</td>\n",
       "      <td>SETEMBRO</td>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>83</td>\n",
       "      <td>BRANCA</td>\n",
       "      <td>CASADO</td>\n",
       "      <td>2O GRAU COMPLETO</td>\n",
       "      <td>1</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>SEXTA-FEIRA</td>\n",
       "      <td>MANHÃ - 00:00:00 A 11:59:59</td>\n",
       "      <td>SETEMBRO</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>50</td>\n",
       "      <td>BRANCA</td>\n",
       "      <td>SOLTEIRO</td>\n",
       "      <td>1O GRAU INCOMPLETO</td>\n",
       "      <td>290</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>SEGUNDA-FEIRA</td>\n",
       "      <td>MANHÃ - 00:00:00 A 11:59:59</td>\n",
       "      <td>NOVEMBRO</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  age    race marital_status            schooling  distance cancer  \\\n",
       "0      F   77  BRANCA         CASADO     1O GRAU COMPLETO         1    NÃO   \n",
       "1      F   46  BRANCA       SOLTEIRO  SUPERIOR INCOMPLETO         1    NÃO   \n",
       "2      F   87  BRANCA         CASADO     2O GRAU COMPLETO         1    SIM   \n",
       "3      F   83  BRANCA         CASADO     2O GRAU COMPLETO         1    NÃO   \n",
       "4      F   50  BRANCA       SOLTEIRO   1O GRAU INCOMPLETO       290    NÃO   \n",
       "\n",
       "             day                        shift     month  lead_time  \\\n",
       "0   QUARTA-FEIRA  MANHÃ - 00:00:00 A 11:59:59  SETEMBRO          6   \n",
       "1    SEXTA-FEIRA  TARDE - 12:00:00 A 23:59:59  NOVEMBRO        478   \n",
       "2  SEGUNDA-FEIRA  MANHÃ - 00:00:00 A 11:59:59  SETEMBRO        195   \n",
       "3    SEXTA-FEIRA  MANHÃ - 00:00:00 A 11:59:59  SETEMBRO          6   \n",
       "4  SEGUNDA-FEIRA  MANHÃ - 00:00:00 A 11:59:59  NOVEMBRO         27   \n",
       "\n",
       "   no_cons_scheduled_previous_year  no_ns_cons_previous_year  \\\n",
       "0                                1                         0   \n",
       "1                               48                        13   \n",
       "2                                3                         0   \n",
       "3                               17                         1   \n",
       "4                                7                         3   \n",
       "\n",
       "   no_exa_scheduled_previous_year  no_ns_exa_previous_year no_show  \n",
       "0                               0                        0     SIM  \n",
       "1                               8                        0     SIM  \n",
       "2                               1                        0     SIM  \n",
       "3                               2                        0     SIM  \n",
       "4                               0                        0     SIM  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object    9\n",
       "int64     7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "le = LabelEncoder()\n",
    "for cl in data.columns:\n",
    "    if data[cl].dtypes==np.object0:\n",
    "        data[cl] = le.fit_transform(data[cl])\n",
    "\n",
    "data.dtypes.value_counts()\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# encoder = OneHotEncoder(sparse=False)\n",
    "# encoded_data = encoder.fit_transform(data[categorical_cols])\n",
    "\n",
    "# encoded_df = pd.concat([data.drop(categorical_cols, axis=1),\n",
    "#                         pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))],\n",
    "#                        axis=1)\n",
    "# data = encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8382 entries, 0 to 8381\n",
      "Data columns (total 16 columns):\n",
      " #   Column                           Non-Null Count  Dtype\n",
      "---  ------                           --------------  -----\n",
      " 0   gender                           8382 non-null   int64\n",
      " 1   age                              8382 non-null   int64\n",
      " 2   race                             8382 non-null   int64\n",
      " 3   marital_status                   8382 non-null   int64\n",
      " 4   schooling                        8382 non-null   int64\n",
      " 5   distance                         8382 non-null   int64\n",
      " 6   cancer                           8382 non-null   int64\n",
      " 7   day                              8382 non-null   int64\n",
      " 8   shift                            8382 non-null   int64\n",
      " 9   month                            8382 non-null   int64\n",
      " 10  lead_time                        8382 non-null   int64\n",
      " 11  no_cons_scheduled_previous_year  8382 non-null   int64\n",
      " 12  no_ns_cons_previous_year         8382 non-null   int64\n",
      " 13  no_exa_scheduled_previous_year   8382 non-null   int64\n",
      " 14  no_ns_exa_previous_year          8382 non-null   int64\n",
      " 15  no_show                          8382 non-null   int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'no_show'\n",
    "X = data.drop([target,'cancer'], axis=1)\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "contingency_table = pd.crosstab(data['race'], data['no_show'])\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(\"Estatística de Teste Chi-Quadrado:\", chi2)\n",
    "print(\"Valor p:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, f_oneway\n",
    "# data[\"a2\"] = data.age*1\n",
    "grouped = data.groupby('no_show')\n",
    "# Realizar o teste t de Student para cada grupo\n",
    "group1 = grouped.get_group(1)['distance']\n",
    "group2 = grouped.get_group(0)['distance']\n",
    "t_statistic, p_value = ttest_ind(group1, group2)\n",
    "# Imprimir os resultados\n",
    "print(\"Estatística t:\", t_statistic)\n",
    "print(\"Valor p:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group1.mean(),group1.std(),group2.mean(),group2.std(),len(group1),len(group2)\n",
    "percentiles = np.linspace(1e-10,1.0-1.e-10,10)\n",
    "variable = 'no_exa_scheduled_previous_year'\n",
    "results = {}\n",
    "for percentile in percentiles:\n",
    "    # Calcular o valor do percentil para a coluna 'age'\n",
    "    age_percentile = data[variable].quantile(percentile)\n",
    "    \n",
    "    # Filtrar o DataFrame com base no percentil\n",
    "    filtered_df = data[data[variable] <= age_percentile]\n",
    "    \n",
    "    # Calcular a proporção de 'no_show' no subconjunto filtrado\n",
    "    no_show_proportion = filtered_df['no_show'].value_counts(normalize=True)\n",
    "    \n",
    "    # Armazenar a proporção no dicionário de resultados\n",
    "    results[age_percentile] = no_show_proportion\n",
    "\n",
    "# Criar um DataFrame a partir do dicionário de resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(\"Proporções de 'no_show' para os percentis:\")\n",
    "results_df\n",
    "results_df.loc[0,:].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>schooling</th>\n",
       "      <th>distance</th>\n",
       "      <th>cancer</th>\n",
       "      <th>day</th>\n",
       "      <th>shift</th>\n",
       "      <th>month</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>no_cons_scheduled_previous_year</th>\n",
       "      <th>no_ns_cons_previous_year</th>\n",
       "      <th>no_exa_scheduled_previous_year</th>\n",
       "      <th>no_ns_exa_previous_year</th>\n",
       "      <th>no_show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "      <td>8382.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.460153</td>\n",
       "      <td>58.419709</td>\n",
       "      <td>1.293128</td>\n",
       "      <td>1.867096</td>\n",
       "      <td>1.575042</td>\n",
       "      <td>57.605703</td>\n",
       "      <td>0.564662</td>\n",
       "      <td>3.029707</td>\n",
       "      <td>0.521832</td>\n",
       "      <td>5.514436</td>\n",
       "      <td>89.389525</td>\n",
       "      <td>10.200907</td>\n",
       "      <td>0.917323</td>\n",
       "      <td>6.090670</td>\n",
       "      <td>0.231090</td>\n",
       "      <td>0.933548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498439</td>\n",
       "      <td>15.972068</td>\n",
       "      <td>0.854865</td>\n",
       "      <td>2.032898</td>\n",
       "      <td>1.395199</td>\n",
       "      <td>99.796573</td>\n",
       "      <td>0.495831</td>\n",
       "      <td>1.423364</td>\n",
       "      <td>0.499553</td>\n",
       "      <td>3.380315</td>\n",
       "      <td>70.742281</td>\n",
       "      <td>10.764909</td>\n",
       "      <td>1.660037</td>\n",
       "      <td>7.189138</td>\n",
       "      <td>0.722537</td>\n",
       "      <td>0.249085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2683.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2415.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender          age         race  marital_status    schooling  \\\n",
       "count  8382.000000  8382.000000  8382.000000     8382.000000  8382.000000   \n",
       "mean      0.460153    58.419709     1.293128        1.867096     1.575042   \n",
       "std       0.498439    15.972068     0.854865        2.032898     1.395199   \n",
       "min       0.000000     0.000000     0.000000        0.000000     0.000000   \n",
       "25%       0.000000    50.000000     1.000000        0.000000     1.000000   \n",
       "50%       0.000000    61.000000     1.000000        1.000000     1.000000   \n",
       "75%       1.000000    69.000000     1.000000        4.000000     2.000000   \n",
       "max       1.000000   102.000000     4.000000        5.000000     6.000000   \n",
       "\n",
       "          distance       cancer          day        shift        month  \\\n",
       "count  8382.000000  8382.000000  8382.000000  8382.000000  8382.000000   \n",
       "mean     57.605703     0.564662     3.029707     0.521832     5.514436   \n",
       "std      99.796573     0.495831     1.423364     0.499553     3.380315   \n",
       "min       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     2.000000     0.000000     3.000000   \n",
       "50%      22.000000     1.000000     3.000000     1.000000     5.000000   \n",
       "75%      78.000000     1.000000     4.000000     1.000000     8.000000   \n",
       "max    2683.000000     1.000000     5.000000     1.000000    11.000000   \n",
       "\n",
       "         lead_time  no_cons_scheduled_previous_year  no_ns_cons_previous_year  \\\n",
       "count  8382.000000                      8382.000000               8382.000000   \n",
       "mean     89.389525                        10.200907                  0.917323   \n",
       "std      70.742281                        10.764909                  1.660037   \n",
       "min       0.000000                         0.000000                  0.000000   \n",
       "25%      43.000000                         2.000000                  0.000000   \n",
       "50%      76.000000                         6.000000                  0.000000   \n",
       "75%     122.000000                        15.000000                  1.000000   \n",
       "max    2415.000000                        85.000000                 19.000000   \n",
       "\n",
       "       no_exa_scheduled_previous_year  no_ns_exa_previous_year      no_show  \n",
       "count                     8382.000000              8382.000000  8382.000000  \n",
       "mean                         6.090670                 0.231090     0.933548  \n",
       "std                          7.189138                 0.722537     0.249085  \n",
       "min                          0.000000                 0.000000     0.000000  \n",
       "25%                          0.000000                 0.000000     1.000000  \n",
       "50%                          4.000000                 0.000000     1.000000  \n",
       "75%                          9.000000                 0.000000     1.000000  \n",
       "max                         48.000000                 9.000000     1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = list(data.columns)\n",
    "sns.set(style = 'ticks', color_codes=True)\n",
    "sns.pairplot(data=data, vars = data[[variables[i] for i in [1,5,10]]] , hue = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=data, x='no_show')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(data= data.corr(), annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,2, figsize=(16,16))\n",
    "sns.distplot(data.var_1, bins = 20, ax=ax[0,0]) \n",
    "sns.distplot(data.var_2, bins = 20, ax=ax[0,1]) \n",
    "sns.distplot(data.var_3, bins = 20, ax=ax[1,0]) \n",
    "sns.distplot(data.var_4, bins = 20, ax=ax[1,1]) \n",
    "sns.distplot(data.var_5, bins = 20, ax=ax[2,0])\n",
    "sns.distplot(data.var_6, bins = 20, ax=ax[2,1])\n",
    "sns.distplot(data.var_7, bins = 20, ax=ax[3,0]) \n",
    "sns.distplot(data.var_8, bins = 20, ax=ax[3,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlations = X.corrwith(y)\n",
    "correlations.sort_values(inplace=True)\n",
    "correlations\n",
    "ax = correlations.plot(kind='bar')\n",
    "ax.set(ylim=[-.1, 0.1], ylabel='pearson correlation')\n",
    "\n",
    "# X.corrwith(data.COMPARECEU_AGENDAMENTO_EXAME).plot.bar(figsize = (15, 10), title = \"Correlation with Target\", fontsize = 10,grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=data.ESTACAO_AGENDAMENTO,y=y,hue=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation Matrix\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = data.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6705 entries, 4589 to 2876\n",
      "Data columns (total 14 columns):\n",
      " #   Column                           Non-Null Count  Dtype\n",
      "---  ------                           --------------  -----\n",
      " 0   gender                           6705 non-null   int64\n",
      " 1   age                              6705 non-null   int64\n",
      " 2   race                             6705 non-null   int64\n",
      " 3   marital_status                   6705 non-null   int64\n",
      " 4   schooling                        6705 non-null   int64\n",
      " 5   distance                         6705 non-null   int64\n",
      " 6   day                              6705 non-null   int64\n",
      " 7   shift                            6705 non-null   int64\n",
      " 8   month                            6705 non-null   int64\n",
      " 9   lead_time                        6705 non-null   int64\n",
      " 10  no_cons_scheduled_previous_year  6705 non-null   int64\n",
      " 11  no_ns_cons_previous_year         6705 non-null   int64\n",
      " 12  no_exa_scheduled_previous_year   6705 non-null   int64\n",
      " 13  no_ns_exa_previous_year          6705 non-null   int64\n",
      "dtypes: int64(14)\n",
      "memory usage: 785.7 KB\n"
     ]
    }
   ],
   "source": [
    "X_tt= pd.DataFrame(X_train,columns=X.columns)\n",
    "X_tt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "classifier = LogisticRegression(random_state=0, penalty='l2')\n",
    "classifier.fit(X_train, y_train)\n",
    "zz = classifier.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18202083, 0.03716733, 0.05479497, ..., 0.05919521, 0.06680544,\n",
       "       0.05209738])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer,f1_score,accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier\n",
    "\n",
    "def minha_metrica(y_true, y_pred):\n",
    "    threshold = 0.5  # Defina o threshold desejado\n",
    "\n",
    "    # Calcule o true positive rate para o threshold dado\n",
    "    tp = np.sum((y_true == 1) & (y_pred >= threshold))\n",
    "    fn = np.sum((y_true == 1) & (y_pred < threshold))\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    # Calcule o true negative rate para o threshold dado\n",
    "    tn = np.sum((y_true == 0) & (y_pred < threshold))\n",
    "    fp = np.sum((y_true == 0) & (y_pred >= threshold))\n",
    "    tnr = tn / (tn + fp)\n",
    "\n",
    "    # Calcule o produto dos passos 1 e 2\n",
    "    product = tpr * tnr\n",
    "\n",
    "    # Retorne a raiz quadrada do passo 3\n",
    "    return np.sqrt(product)\n",
    "\n",
    "my_scorer = make_scorer(minha_metrica,greater_is_better=True)\n",
    "\n",
    "piplr = Pipeline([('escala',MinMaxScaler()),('modelo', LogisticRegression(penalty='l2'))])\n",
    "cvr = cross_validate(piplr,X_train, y_train,scoring = my_scorer, cv=3,return_estimator=True)\n",
    "cvr['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = cvr['estimator']\n",
    "best_model = estimators[np.argmax(cvr['test_score'])]\n",
    "best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01434112, 0.01267791, 0.11358285]),\n",
       " 'score_time': array([0.00255108, 0.00219512, 0.00205803]),\n",
       " 'estimator': [Pipeline(steps=[('escala', StandardScaler()), ('modelo', LogisticRegression())]),\n",
       "  Pipeline(steps=[('escala', StandardScaler()), ('modelo', LogisticRegression())]),\n",
       "  Pipeline(steps=[('escala', StandardScaler()), ('modelo', LogisticRegression())])],\n",
       " 'test_score': array([0.93333333, 0.93333333, 0.93333333])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;escala&#x27;, StandardScaler()), (&#x27;modelo&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;escala&#x27;, StandardScaler()), (&#x27;modelo&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('escala', StandardScaler()), ('modelo', LogisticRegression())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score,recall_score,precision_score, confusion_matrix\n",
    "# classifier = LogisticRegression(penalty='l2')\n",
    "kf =  StratifiedKFold(n_splits=5)\n",
    "scr = []\n",
    "pipe = Pipeline([('escala',StandardScaler()),('modelo', LogisticRegression(penalty='l2'))])\n",
    "for train, test in kf.split(X,y):\n",
    "    Xtr,Xts = X.iloc[train,:],X.iloc[test,:]\n",
    "    ytr,yts = y[train],y[test]\n",
    "    pipe.fit(Xtr,ytr)\n",
    "    ypr = pipe.predict(Xts)\n",
    "    cm = confusion_matrix(yts,ypr,normalize='true')\n",
    "    scr.append(np.sqrt(cm[0][0]*cm[1][1]))\n",
    "    \n",
    "print(scr)\n",
    "    # classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score,recall_score,precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "kf =  StratifiedKFold(n_splits=5)\n",
    "scr = []\n",
    "poly = PolynomialFeatures(degree=5)\n",
    "pipe = Pipeline([(('poli',poly)),('escala',StandardScaler()),('modelo', LogisticRegression(penalty='l2'))])\n",
    "for train, test in kf.split(X,y):\n",
    "    Xtr,Xts = X.iloc[train,:],X.iloc[test,:]\n",
    "    ytr,yts = y[train],y[test]\n",
    "    pipe.fit(Xtr,ytr)\n",
    "    ypr = pipe.predict(Xts)\n",
    "    cm = confusion_matrix(yts,ypr,normalize='true')\n",
    "    # scr.append(np.sqrt(cm[0][0]*cm[1][1]))\n",
    "    scr.append(accuracy_score(yts,ypr))\n",
    "    \n",
    "print(scr)\n",
    "    # classifier.fit(X_train, y_train)\n",
    "\n",
    "# scr2 = cross_val_score(pipe,X,y,cv = 5)\n",
    "# print(scr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24286587, 0.22821029, 0.21611757])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer,f1_score,accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso,\n",
    "\n",
    "\n",
    "def minha_metrica(y_true, y_pred):\n",
    "    threshold = 0.5  # Defina o threshold desejado\n",
    "    \n",
    "\n",
    "    # Calcule o true positive rate para o threshold dado\n",
    "    tp = np.sum((y_true == 1) & (y_pred >= threshold))\n",
    "    fn = np.sum((y_true == 1) & (y_pred < threshold))\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    # Calcule o true negative rate para o threshold dado\n",
    "    tn = np.sum((y_true == 0) & (y_pred < threshold))\n",
    "    fp = np.sum((y_true == 0) & (y_pred >= threshold))\n",
    "    tnr = tn / (tn + fp)\n",
    "\n",
    "    # Calcule o produto dos passos 1 e 2\n",
    "    product = tpr * tnr\n",
    "\n",
    "    # Retorne a raiz quadrada do passo 3\n",
    "    return np.sqrt(product)\n",
    "\n",
    "my_scorer = make_scorer(minha_metrica,greater_is_better=True)\n",
    "\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "# pipe = Pipeline([(('poli',poly)),('escala',StandardScaler()),('modelo', LogisticRegression(penalty='l2'))]) \n",
    "# pipe = Pipeline([('escala',StandardScaler()),(('poli',poly)),('modelo', LogisticRegression(penalty='l2'))])\n",
    "pipe = Pipeline([(('poli',poly)),('escala',StandardScaler()),('modelo', Lasso(alpha = .0001, max_iter=100000))])\n",
    "cvr = cross_validate(pipe, X_train, y_train, cv=3, scoring=my_scorer, return_estimator=True)\n",
    "cvr['test_score']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2806936 , 0.26737558, 0.25505879])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = cvr['estimator']\n",
    "best_model = estimators[np.argmax(cvr['test_score'])]\n",
    "# coefs = best_model.named_steps['modelo'].coef_[0]\n",
    "cvr['test_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54,  57],\n",
       "       [867, 699]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_model.predict_proba(X_test)[:,0]\n",
    "confusion_matrix(y_test,y_pred>=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, f1_score,recall_score,precision_score, confusion_matrix\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "results = pd.DataFrame([['Logistic Regression (Lasso)', acc,prec,rec,f1]],columns=['Model', 'Accuracy', 'Precision', 'Recall','F1 Score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = classifier.predict_proba(X_test)\n",
    "from scipy import integrate\n",
    "def capcurve(y_values, y_preds_proba):\n",
    "    num_pos_obs = np.sum(y_values)\n",
    "    num_count = len(y_values)\n",
    "    rate_pos_obs = float(num_pos_obs) / float(num_count)\n",
    "    ideal = pd.DataFrame({'x':[0,rate_pos_obs,1],'y':[0,1,1]})\n",
    "    xx = np.arange(num_count) / float(num_count - 1)\n",
    "    \n",
    "    y_cap = np.c_[y_values,y_preds_proba]\n",
    "    y_cap_df_s = pd.DataFrame(data=y_cap)\n",
    "    y_cap_df_s = y_cap_df_s.sort_values([1], ascending=False).reset_index(level = y_cap_df_s.index.names, drop=True)\n",
    "    \n",
    "    print(y_cap_df_s.head(20))\n",
    "    \n",
    "    yy = np.cumsum(y_cap_df_s[0]) / float(num_pos_obs)\n",
    "    yy = np.append([0], yy[0:num_count-1]) #add the first curve point (0,0) : for xx=0 we have yy=0\n",
    "    \n",
    "    percent = 0.5\n",
    "    row_index = int(np.trunc(num_count * percent))\n",
    "    \n",
    "    val_y1 = yy[row_index]\n",
    "    val_y2 = yy[row_index+1]\n",
    "    if val_y1 == val_y2:\n",
    "        val = val_y1*1.0\n",
    "    else:\n",
    "        val_x1 = xx[row_index]\n",
    "        val_x2 = xx[row_index+1]\n",
    "        val = val_y1 + ((val_x2 - percent)/(val_x2 - val_x1))*(val_y2 - val_y1)\n",
    "    \n",
    "    sigma_ideal = 1 * xx[num_pos_obs - 1 ] / 2 + (xx[num_count - 1] - xx[num_pos_obs]) * 1\n",
    "    sigma_model = integrate.simps(yy,xx)\n",
    "    sigma_random = integrate.simps(xx,xx)\n",
    "    \n",
    "    ar_value = (sigma_model - sigma_random) / (sigma_ideal - sigma_random)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 1)\n",
    "    ax.plot(ideal['x'],ideal['y'], color='grey', label='Perfect Model')\n",
    "    ax.plot(xx,yy, color='red', label='User Model')\n",
    "    ax.plot(xx,xx, color='blue', label='Random Model')\n",
    "    ax.plot([percent, percent], [0.0, val], color='green', linestyle='--', linewidth=1)\n",
    "    ax.plot([0, percent], [val, val], color='green', linestyle='--', linewidth=1, label=str(val*100)+'% of positive obs at '+str(percent*100)+'%')\n",
    "    \n",
    "    plt.xlim(0, 1.02)\n",
    "    plt.ylim(0, 1.25)\n",
    "    plt.title(\"CAP Curve - a_r value =\"+str(ar_value))\n",
    "    plt.xlabel('% of the data')\n",
    "    plt.ylabel('% of positive obs')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capcurve(y_test,y_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator= classifier, X=X_train, y=y_train, cv=10)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "print('Logistic Regression (Lasso) Accuracy: %0.3f (+/- %0.3f)' % (accuracies.mean(), accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_train.columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection \n",
    "#Recursive feature elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Select best feature \n",
    "rfe = RFE(classifier, n_features_to_select= None)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "#Summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Correlation Matrix\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = X_train[X_train.columns[rfe.support_]].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(18, 15))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0, penalty= 'l2')\n",
    "classifier.fit(X_train[X_train.columns[rfe.support_]], y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test[X_train.columns[rfe.support_]])\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Logistic Regression RFE (Lasso)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = classifier.predict_proba(X_test[X_train.columns[rfe.support_]])\n",
    "capcurve(y_test,y_pred_prob[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
